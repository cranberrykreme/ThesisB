{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('liar_dataset/test.tsv', sep='\\t', header=None) \n",
    "valid = pd.read_csv('liar_dataset/valid.tsv', sep='\\t', header=None)\n",
    "\n",
    "#Adding Columns - test\n",
    "test.columns=[\"Statement_ID\",\"Label\", \"Statement\", \"Subject(s)\", \"Speaker\", \"Speaker_Job\", \"State\", \"Party\", \"Barely_True_History\", \n",
    "             \"False_History\", \"Half_True_History\", \"Mostly_True_History\", \"Pants_On_Fire_History\",\"Context\"]\n",
    "\n",
    "#Adding Columns - valid\n",
    "valid.columns=[\"Statement_ID\",\"Label\", \"Statement\", \"Subject(s)\", \"Speaker\", \"Speaker_Job\", \"State\", \"Party\", \"Barely_True_History\", \n",
    "             \"False_History\", \"Half_True_History\", \"Mostly_True_History\", \"Pants_On_Fire_History\",\"Context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correctly loads the dataset with no wrong columns\n",
    "train = pd.read_csv('liar_dataset/train.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statement_ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Subject(s)</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Speaker_Job</th>\n",
       "      <th>State</th>\n",
       "      <th>Party</th>\n",
       "      <th>Barely_True_History</th>\n",
       "      <th>False_History</th>\n",
       "      <th>Half_True_History</th>\n",
       "      <th>Mostly_True_History</th>\n",
       "      <th>Pants_On_Fire_History</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Statement_ID        Label  \\\n",
       "0    2635.json        false   \n",
       "1   10540.json    half-true   \n",
       "2     324.json  mostly-true   \n",
       "3    1123.json        false   \n",
       "4    9028.json    half-true   \n",
       "\n",
       "                                           Statement  \\\n",
       "0  Says the Annies List political group supports ...   \n",
       "1  When did the decline of coal start? It started...   \n",
       "2  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3  Health care reform legislation is likely to ma...   \n",
       "4  The economic turnaround started at the end of ...   \n",
       "\n",
       "                           Subject(s)         Speaker           Speaker_Job  \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "3                         health-care    blog-posting                   NaN   \n",
       "4                        economy,jobs   charlie-crist                   NaN   \n",
       "\n",
       "      State       Party  Barely_True_History  False_History  \\\n",
       "0     Texas  republican                  0.0            1.0   \n",
       "1  Virginia    democrat                  0.0            0.0   \n",
       "2  Illinois    democrat                 70.0           71.0   \n",
       "3       NaN        none                  7.0           19.0   \n",
       "4   Florida    democrat                 15.0            9.0   \n",
       "\n",
       "   Half_True_History  Mostly_True_History  Pants_On_Fire_History  \\\n",
       "0                0.0                  0.0                    0.0   \n",
       "1                1.0                  1.0                    0.0   \n",
       "2              160.0                163.0                    9.0   \n",
       "3                3.0                  5.0                   44.0   \n",
       "4               20.0                 19.0                    2.0   \n",
       "\n",
       "               Context  \n",
       "0             a mailer  \n",
       "1      a floor speech.  \n",
       "2               Denver  \n",
       "3       a news release  \n",
       "4  an interview on CNN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding Columns\n",
    "train.columns=[\"Statement_ID\",\"Label\", \"Statement\", \"Subject(s)\", \"Speaker\", \"Speaker_Job\", \"State\", \"Party\", \"Barely_True_History\", \n",
    "             \"False_History\", \"Half_True_History\", \"Mostly_True_History\", \"Pants_On_Fire_History\",\"Context\"]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine sets to have same number of features towards the end\n",
    "df = pd.concat([train, test, valid], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan in each columns:\n",
      "Statement_ID                0\n",
      "Label                       0\n",
      "Statement                   0\n",
      "Subject(s)                  2\n",
      "Speaker                     2\n",
      "Speaker_Job              3567\n",
      "State                    2749\n",
      "Party                       2\n",
      "Barely_True_History         2\n",
      "False_History               2\n",
      "Half_True_History           2\n",
      "Mostly_True_History         2\n",
      "Pants_On_Fire_History       2\n",
      "Context                   131\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Nan in each columns:\" , df.isna().sum(), sep='\\n')#print out the number of NaN entries in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing NaN\n",
    "df['Barely_True_History'] = df['Barely_True_History'].fillna(0.0) # Fill NaN with 0.0\n",
    "df['False_History'] = df['False_History'].fillna(0.0) # Fill NaN with 0.0\n",
    "df['Half_True_History'] = df['Half_True_History'].fillna(0.0) # Fill NaN with 0.0\n",
    "df['Mostly_True_History'] = df['Mostly_True_History'].fillna(0.0) # Fill NaN with 0.0\n",
    "df['Pants_On_Fire_History'] = df['Pants_On_Fire_History'].fillna(0.0) # Fill NaN with 0.0\n",
    "\n",
    "df = df.fillna(0.0) # fill all NaN with 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan in each columns:\n",
      "Statement_ID             0\n",
      "Label                    0\n",
      "Statement                0\n",
      "Subject(s)               0\n",
      "Speaker                  0\n",
      "Speaker_Job              0\n",
      "State                    0\n",
      "Party                    0\n",
      "Barely_True_History      0\n",
      "False_History            0\n",
      "Half_True_History        0\n",
      "Mostly_True_History      0\n",
      "Pants_On_Fire_History    0\n",
      "Context                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Nan in each columns:\" , df.isna().sum(), sep='\\n')#print out the number of NaN entries in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label                                          Statement\n",
       "0        false  Says the Annies List political group supports ...\n",
       "1    half-true  When did the decline of coal start? It started...\n",
       "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...\n",
       "3        false  Health care reform legislation is likely to ma...\n",
       "4    half-true  The economic turnaround started at the end of ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df[['Label', 'Statement']].copy() # Make copy dataset to work off of.\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>body_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>When did the decline of coal start It started ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>Hillary Clinton agrees with John McCain by vot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label                                          Statement  \\\n",
       "0        false  Says the Annies List political group supports ...   \n",
       "1    half-true  When did the decline of coal start? It started...   \n",
       "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3        false  Health care reform legislation is likely to ma...   \n",
       "4    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                     body_text_clean  \n",
       "0  Says the Annies List political group supports ...  \n",
       "1  When did the decline of coal start It started ...  \n",
       "2  Hillary Clinton agrees with John McCain by vot...  \n",
       "3  Health care reform legislation is likely to ma...  \n",
       "4  The economic turnaround started at the end of ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct\n",
    "\n",
    "df_clean['body_text_clean'] = df_clean['Statement'].apply(lambda x: remove_punct(x))\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>[says, the, annies, list, political, group, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>When did the decline of coal start It started ...</td>\n",
       "      <td>[when, did, the, decline, of, coal, start, it,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>Hillary Clinton agrees with John McCain by vot...</td>\n",
       "      <td>[hillary, clinton, agrees, with, john, mccain,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>[health, care, reform, legislation, is, likely...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>[the, economic, turnaround, started, at, the, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label                                          Statement  \\\n",
       "0        false  Says the Annies List political group supports ...   \n",
       "1    half-true  When did the decline of coal start? It started...   \n",
       "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3        false  Health care reform legislation is likely to ma...   \n",
       "4    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Says the Annies List political group supports ...   \n",
       "1  When did the decline of coal start It started ...   \n",
       "2  Hillary Clinton agrees with John McCain by vot...   \n",
       "3  Health care reform legislation is likely to ma...   \n",
       "4  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                 body_text_tokenized  \n",
       "0  [says, the, annies, list, political, group, su...  \n",
       "1  [when, did, the, decline, of, coal, start, it,...  \n",
       "2  [hillary, clinton, agrees, with, john, mccain,...  \n",
       "3  [health, care, reform, legislation, is, likely...  \n",
       "4  [the, economic, turnaround, started, at, the, ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    #tokens = \" \".join(word for word in tokens)\n",
    "    return tokens\n",
    "\n",
    "df_clean['body_text_tokenized'] = df_clean['body_text_clean'].apply(lambda x: tokenize(x.lower()))\n",
    "\n",
    "\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>[says, the, annies, list, political, group, su...</td>\n",
       "      <td>[says, annies, list, political, group, support...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>When did the decline of coal start It started ...</td>\n",
       "      <td>[when, did, the, decline, of, coal, start, it,...</td>\n",
       "      <td>[decline, coal, start, started, natural, gas, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>Hillary Clinton agrees with John McCain by vot...</td>\n",
       "      <td>[hillary, clinton, agrees, with, john, mccain,...</td>\n",
       "      <td>[hillary, clinton, agrees, john, mccain, votin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>[health, care, reform, legislation, is, likely...</td>\n",
       "      <td>[health, care, reform, legislation, likely, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>[the, economic, turnaround, started, at, the, ...</td>\n",
       "      <td>[economic, turnaround, started, end, term]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label                                          Statement  \\\n",
       "0        false  Says the Annies List political group supports ...   \n",
       "1    half-true  When did the decline of coal start? It started...   \n",
       "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3        false  Health care reform legislation is likely to ma...   \n",
       "4    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Says the Annies List political group supports ...   \n",
       "1  When did the decline of coal start It started ...   \n",
       "2  Hillary Clinton agrees with John McCain by vot...   \n",
       "3  Health care reform legislation is likely to ma...   \n",
       "4  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [says, the, annies, list, political, group, su...   \n",
       "1  [when, did, the, decline, of, coal, start, it,...   \n",
       "2  [hillary, clinton, agrees, with, john, mccain,...   \n",
       "3  [health, care, reform, legislation, is, likely...   \n",
       "4  [the, economic, turnaround, started, at, the, ...   \n",
       "\n",
       "                                    body_text_nostop  \n",
       "0  [says, annies, list, political, group, support...  \n",
       "1  [decline, coal, start, started, natural, gas, ...  \n",
       "2  [hillary, clinton, agrees, john, mccain, votin...  \n",
       "3  [health, care, reform, legislation, likely, ma...  \n",
       "4         [economic, turnaround, started, end, term]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(tokenized_list):\n",
    "    text = [word for word in tokenized_list if word not in stopword]\n",
    "    return text\n",
    "\n",
    "df_clean['body_text_nostop'] = df_clean['body_text_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing/Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "      <th>body_text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>[says, the, annies, list, political, group, su...</td>\n",
       "      <td>[says, annies, list, political, group, support...</td>\n",
       "      <td>[say, annies, list, political, group, support,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>When did the decline of coal start It started ...</td>\n",
       "      <td>[when, did, the, decline, of, coal, start, it,...</td>\n",
       "      <td>[decline, coal, start, started, natural, gas, ...</td>\n",
       "      <td>[decline, coal, start, started, natural, gas, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>Hillary Clinton agrees with John McCain by vot...</td>\n",
       "      <td>[hillary, clinton, agrees, with, john, mccain,...</td>\n",
       "      <td>[hillary, clinton, agrees, john, mccain, votin...</td>\n",
       "      <td>[hillary, clinton, agrees, john, mccain, votin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>[health, care, reform, legislation, is, likely...</td>\n",
       "      <td>[health, care, reform, legislation, likely, ma...</td>\n",
       "      <td>[health, care, reform, legislation, likely, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>[the, economic, turnaround, started, at, the, ...</td>\n",
       "      <td>[economic, turnaround, started, end, term]</td>\n",
       "      <td>[economic, turnaround, started, end, term]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label                                          Statement  \\\n",
       "0        false  Says the Annies List political group supports ...   \n",
       "1    half-true  When did the decline of coal start? It started...   \n",
       "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3        false  Health care reform legislation is likely to ma...   \n",
       "4    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Says the Annies List political group supports ...   \n",
       "1  When did the decline of coal start It started ...   \n",
       "2  Hillary Clinton agrees with John McCain by vot...   \n",
       "3  Health care reform legislation is likely to ma...   \n",
       "4  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [says, the, annies, list, political, group, su...   \n",
       "1  [when, did, the, decline, of, coal, start, it,...   \n",
       "2  [hillary, clinton, agrees, with, john, mccain,...   \n",
       "3  [health, care, reform, legislation, is, likely...   \n",
       "4  [the, economic, turnaround, started, at, the, ...   \n",
       "\n",
       "                                    body_text_nostop  \\\n",
       "0  [says, annies, list, political, group, support...   \n",
       "1  [decline, coal, start, started, natural, gas, ...   \n",
       "2  [hillary, clinton, agrees, john, mccain, votin...   \n",
       "3  [health, care, reform, legislation, likely, ma...   \n",
       "4         [economic, turnaround, started, end, term]   \n",
       "\n",
       "                                body_text_lemmatized  \n",
       "0  [say, annies, list, political, group, support,...  \n",
       "1  [decline, coal, start, started, natural, gas, ...  \n",
       "2  [hillary, clinton, agrees, john, mccain, votin...  \n",
       "3  [health, care, reform, legislation, likely, ma...  \n",
       "4         [economic, turnaround, started, end, term]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatizing is more accurate but slower\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizing(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text\n",
    "\n",
    "df_clean['body_text_lemmatized'] = df_clean['body_text_nostop'].apply(lambda x: lemmatizing(x))\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "      <th>body_text_lemmatized</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>[says, the, annies, list, political, group, su...</td>\n",
       "      <td>[says, annies, list, political, group, support...</td>\n",
       "      <td>[say, annies, list, political, group, support,...</td>\n",
       "      <td>say annies list political group support thirdt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>When did the decline of coal start It started ...</td>\n",
       "      <td>[when, did, the, decline, of, coal, start, it,...</td>\n",
       "      <td>[decline, coal, start, started, natural, gas, ...</td>\n",
       "      <td>[decline, coal, start, started, natural, gas, ...</td>\n",
       "      <td>decline coal start started natural gas took st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>Hillary Clinton agrees with John McCain by vot...</td>\n",
       "      <td>[hillary, clinton, agrees, with, john, mccain,...</td>\n",
       "      <td>[hillary, clinton, agrees, john, mccain, votin...</td>\n",
       "      <td>[hillary, clinton, agrees, john, mccain, votin...</td>\n",
       "      <td>hillary clinton agrees john mccain voting give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>[health, care, reform, legislation, is, likely...</td>\n",
       "      <td>[health, care, reform, legislation, likely, ma...</td>\n",
       "      <td>[health, care, reform, legislation, likely, ma...</td>\n",
       "      <td>health care reform legislation likely mandate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>[the, economic, turnaround, started, at, the, ...</td>\n",
       "      <td>[economic, turnaround, started, end, term]</td>\n",
       "      <td>[economic, turnaround, started, end, term]</td>\n",
       "      <td>economic turnaround started end term</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label                                          Statement  \\\n",
       "0        false  Says the Annies List political group supports ...   \n",
       "1    half-true  When did the decline of coal start? It started...   \n",
       "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3        false  Health care reform legislation is likely to ma...   \n",
       "4    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Says the Annies List political group supports ...   \n",
       "1  When did the decline of coal start It started ...   \n",
       "2  Hillary Clinton agrees with John McCain by vot...   \n",
       "3  Health care reform legislation is likely to ma...   \n",
       "4  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [says, the, annies, list, political, group, su...   \n",
       "1  [when, did, the, decline, of, coal, start, it,...   \n",
       "2  [hillary, clinton, agrees, with, john, mccain,...   \n",
       "3  [health, care, reform, legislation, is, likely...   \n",
       "4  [the, economic, turnaround, started, at, the, ...   \n",
       "\n",
       "                                    body_text_nostop  \\\n",
       "0  [says, annies, list, political, group, support...   \n",
       "1  [decline, coal, start, started, natural, gas, ...   \n",
       "2  [hillary, clinton, agrees, john, mccain, votin...   \n",
       "3  [health, care, reform, legislation, likely, ma...   \n",
       "4         [economic, turnaround, started, end, term]   \n",
       "\n",
       "                                body_text_lemmatized  \\\n",
       "0  [say, annies, list, political, group, support,...   \n",
       "1  [decline, coal, start, started, natural, gas, ...   \n",
       "2  [hillary, clinton, agrees, john, mccain, votin...   \n",
       "3  [health, care, reform, legislation, likely, ma...   \n",
       "4         [economic, turnaround, started, end, term]   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  say annies list political group support thirdt...  \n",
       "1  decline coal start started natural gas took st...  \n",
       "2  hillary clinton agrees john mccain voting give...  \n",
       "3  health care reform legislation likely mandate ...  \n",
       "4               economic turnaround started end term  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are a few different types of vectorization:\n",
    "# 1. Count Vectorization: Takes single words\n",
    "# 2. N-grams: Takes groups of words (i.e. strings)\n",
    "# 3. Term frequency - inverse document frequency (TF-IDF): Back to single words\n",
    "# For the testing purposes of this Thesis, we can just start by using TF-IDF (N-grams too long, CV not too bad)\n",
    "\n",
    "# Make list into single string\n",
    "def toll(text):\n",
    "    text = \" \".join(word for word in text)\n",
    "    return text\n",
    "\n",
    "df_clean['cleaned_text'] = df_clean['body_text_lemmatized'].apply(lambda x: toll(x))\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12791, 13141)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vect.fit_transform(df_clean['cleaned_text']) # Read in the pre-processed data\n",
    "\n",
    "print(X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>004</th>\n",
       "      <th>005</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>025</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>047</th>\n",
       "      <th>05</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>zippo</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zuckerbergs</th>\n",
       "      <th>zvisa</th>\n",
       "      <th>ʺmore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12786</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12789</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12790</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12791 rows × 13141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00  004  005   01   02  025   03   04  047   05  ...  zip  zippo  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...   \n",
       "12786  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "12787  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "12788  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "12789  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "12790  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "\n",
       "       zombie  zone  zoning  zoo  zuckerberg  zuckerbergs  zvisa  ʺmore  \n",
       "0         0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "1         0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "2         0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "3         0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "4         0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "...       ...   ...     ...  ...         ...          ...    ...    ...  \n",
       "12786     0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "12787     0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "12788     0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "12789     0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "12790     0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "\n",
       "[12791 rows x 13141 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a matrix with the TF-IDF values\n",
    "X_tfidf_df = pd.DataFrame(X_tfidf.toarray())\n",
    "\n",
    "# Add column names\n",
    "X_tfidf_df.columns = tfidf_vect.get_feature_names()\n",
    "\n",
    "\n",
    "X_tfidf_df #product of all of the preprocessing\n",
    "\n",
    "# NOTE, in the end this was found to be too many features and so this TF-IDF section was dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject(s)</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Speaker_Job</th>\n",
       "      <th>State</th>\n",
       "      <th>Party</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>0</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12786</th>\n",
       "      <td>energy,oil-spill,trade</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>a press conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>candidates-biography</td>\n",
       "      <td>hillary-clinton</td>\n",
       "      <td>Presidential candidate</td>\n",
       "      <td>New York</td>\n",
       "      <td>democrat</td>\n",
       "      <td>a speech on the economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>health-care</td>\n",
       "      <td>campaign-defend-america</td>\n",
       "      <td>0</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>none</td>\n",
       "      <td>a television ad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12789</th>\n",
       "      <td>health-care</td>\n",
       "      <td>americans-united-change</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>an Internet ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12790</th>\n",
       "      <td>candidates-biography,infrastructure</td>\n",
       "      <td>rudy-giuliani</td>\n",
       "      <td>Attorney</td>\n",
       "      <td>New York</td>\n",
       "      <td>republican</td>\n",
       "      <td>comments on NBC's \"Meet the Press\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12791 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Subject(s)                  Speaker  \\\n",
       "0                                 abortion             dwayne-bohac   \n",
       "1       energy,history,job-accomplishments           scott-surovell   \n",
       "2                           foreign-policy             barack-obama   \n",
       "3                              health-care             blog-posting   \n",
       "4                             economy,jobs            charlie-crist   \n",
       "...                                    ...                      ...   \n",
       "12786               energy,oil-spill,trade             barack-obama   \n",
       "12787                 candidates-biography          hillary-clinton   \n",
       "12788                          health-care  campaign-defend-america   \n",
       "12789                          health-care  americans-united-change   \n",
       "12790  candidates-biography,infrastructure            rudy-giuliani   \n",
       "\n",
       "                  Speaker_Job             State       Party  \\\n",
       "0        State representative             Texas  republican   \n",
       "1              State delegate          Virginia    democrat   \n",
       "2                   President          Illinois    democrat   \n",
       "3                           0                 0        none   \n",
       "4                           0           Florida    democrat   \n",
       "...                       ...               ...         ...   \n",
       "12786               President          Illinois    democrat   \n",
       "12787  Presidential candidate          New York    democrat   \n",
       "12788                       0  Washington, D.C.        none   \n",
       "12789                       0                 0        none   \n",
       "12790                Attorney          New York  republican   \n",
       "\n",
       "                                  Context  \n",
       "0                                a mailer  \n",
       "1                         a floor speech.  \n",
       "2                                  Denver  \n",
       "3                          a news release  \n",
       "4                     an interview on CNN  \n",
       "...                                   ...  \n",
       "12786                  a press conference  \n",
       "12787             a speech on the economy  \n",
       "12788                     a television ad  \n",
       "12789                     an Internet ad.  \n",
       "12790  comments on NBC's \"Meet the Press\"  \n",
       "\n",
       "[12791 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use one hot encoding to convert categorical values into numerical values\n",
    "# First remove the columns we won't use\n",
    "hot_coding_data = df.copy()\n",
    "hot_coding_data = hot_coding_data.drop(columns = ['Statement_ID', 'Label', 'Statement', \n",
    "                                                  'Barely_True_History', 'False_History', \n",
    "                                                  'Half_True_History','Mostly_True_History',\n",
    "                                                  'Pants_On_Fire_History'])\n",
    "\n",
    "hot_coding_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put all of the columns into numerical values using one hot encoding.\n",
    "hot_coding_data = pd.get_dummies(hot_coding_data, columns=['Subject(s)'], prefix = '', drop_first = False)\n",
    "hot_coding_data = pd.get_dummies(hot_coding_data, columns=['Speaker'], prefix = '', drop_first = False)\n",
    "hot_coding_data = pd.get_dummies(hot_coding_data, columns=['Speaker_Job'], prefix = '', drop_first = False)\n",
    "hot_coding_data = pd.get_dummies(hot_coding_data, columns=['State'], prefix = '', drop_first = False)\n",
    "hot_coding_data = pd.get_dummies(hot_coding_data, columns=['Party'], prefix = '', drop_first = False)\n",
    "hot_coding_data = pd.get_dummies(hot_coding_data, columns=['Context'], prefix = '', drop_first = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_0.0</th>\n",
       "      <th>_Alcohol</th>\n",
       "      <th>_Alcohol,animals,children,crime</th>\n",
       "      <th>_Alcohol,campaign-finance,ethics,public-service</th>\n",
       "      <th>_Alcohol,candidates-biography</th>\n",
       "      <th>_Alcohol,candidates-biography,crime</th>\n",
       "      <th>_Alcohol,children</th>\n",
       "      <th>_Alcohol,children,crime,public-health,public-safety</th>\n",
       "      <th>_Alcohol,children,drugs,marijuana</th>\n",
       "      <th>_Alcohol,city-government</th>\n",
       "      <th>...</th>\n",
       "      <th>_website posting.</th>\n",
       "      <th>_weekly Senate Republican radio address</th>\n",
       "      <th>_while interviewing Donald Trump in Austin</th>\n",
       "      <th>_whylarrywhy.com</th>\n",
       "      <th>_women's conference session</th>\n",
       "      <th>_written testimony at a House hearing</th>\n",
       "      <th>_written testimony to a Wisconsin Senate committee</th>\n",
       "      <th>_x</th>\n",
       "      <th>_yard signs posted anonymously opposing a proposed office park redevelopment in Northwest Austin</th>\n",
       "      <th>_“Voters Guide,” League of Women Voters of the Austin Area.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12786</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12789</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12790</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12791 rows × 14455 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       _0.0  _Alcohol  _Alcohol,animals,children,crime  \\\n",
       "0         0         0                                0   \n",
       "1         0         0                                0   \n",
       "2         0         0                                0   \n",
       "3         0         0                                0   \n",
       "4         0         0                                0   \n",
       "...     ...       ...                              ...   \n",
       "12786     0         0                                0   \n",
       "12787     0         0                                0   \n",
       "12788     0         0                                0   \n",
       "12789     0         0                                0   \n",
       "12790     0         0                                0   \n",
       "\n",
       "       _Alcohol,campaign-finance,ethics,public-service  \\\n",
       "0                                                    0   \n",
       "1                                                    0   \n",
       "2                                                    0   \n",
       "3                                                    0   \n",
       "4                                                    0   \n",
       "...                                                ...   \n",
       "12786                                                0   \n",
       "12787                                                0   \n",
       "12788                                                0   \n",
       "12789                                                0   \n",
       "12790                                                0   \n",
       "\n",
       "       _Alcohol,candidates-biography  _Alcohol,candidates-biography,crime  \\\n",
       "0                                  0                                    0   \n",
       "1                                  0                                    0   \n",
       "2                                  0                                    0   \n",
       "3                                  0                                    0   \n",
       "4                                  0                                    0   \n",
       "...                              ...                                  ...   \n",
       "12786                              0                                    0   \n",
       "12787                              0                                    0   \n",
       "12788                              0                                    0   \n",
       "12789                              0                                    0   \n",
       "12790                              0                                    0   \n",
       "\n",
       "       _Alcohol,children  _Alcohol,children,crime,public-health,public-safety  \\\n",
       "0                      0                                                  0     \n",
       "1                      0                                                  0     \n",
       "2                      0                                                  0     \n",
       "3                      0                                                  0     \n",
       "4                      0                                                  0     \n",
       "...                  ...                                                ...     \n",
       "12786                  0                                                  0     \n",
       "12787                  0                                                  0     \n",
       "12788                  0                                                  0     \n",
       "12789                  0                                                  0     \n",
       "12790                  0                                                  0     \n",
       "\n",
       "       _Alcohol,children,drugs,marijuana  _Alcohol,city-government  ...  \\\n",
       "0                                      0                         0  ...   \n",
       "1                                      0                         0  ...   \n",
       "2                                      0                         0  ...   \n",
       "3                                      0                         0  ...   \n",
       "4                                      0                         0  ...   \n",
       "...                                  ...                       ...  ...   \n",
       "12786                                  0                         0  ...   \n",
       "12787                                  0                         0  ...   \n",
       "12788                                  0                         0  ...   \n",
       "12789                                  0                         0  ...   \n",
       "12790                                  0                         0  ...   \n",
       "\n",
       "       _website posting.  _weekly Senate Republican radio address  \\\n",
       "0                      0                                        0   \n",
       "1                      0                                        0   \n",
       "2                      0                                        0   \n",
       "3                      0                                        0   \n",
       "4                      0                                        0   \n",
       "...                  ...                                      ...   \n",
       "12786                  0                                        0   \n",
       "12787                  0                                        0   \n",
       "12788                  0                                        0   \n",
       "12789                  0                                        0   \n",
       "12790                  0                                        0   \n",
       "\n",
       "       _while interviewing Donald Trump in Austin  _whylarrywhy.com  \\\n",
       "0                                               0                 0   \n",
       "1                                               0                 0   \n",
       "2                                               0                 0   \n",
       "3                                               0                 0   \n",
       "4                                               0                 0   \n",
       "...                                           ...               ...   \n",
       "12786                                           0                 0   \n",
       "12787                                           0                 0   \n",
       "12788                                           0                 0   \n",
       "12789                                           0                 0   \n",
       "12790                                           0                 0   \n",
       "\n",
       "       _women's conference session  _written testimony at a House hearing  \\\n",
       "0                                0                                      0   \n",
       "1                                0                                      0   \n",
       "2                                0                                      0   \n",
       "3                                0                                      0   \n",
       "4                                0                                      0   \n",
       "...                            ...                                    ...   \n",
       "12786                            0                                      0   \n",
       "12787                            0                                      0   \n",
       "12788                            0                                      0   \n",
       "12789                            0                                      0   \n",
       "12790                            0                                      0   \n",
       "\n",
       "       _written testimony to a Wisconsin Senate committee  _x  \\\n",
       "0                                                      0    0   \n",
       "1                                                      0    0   \n",
       "2                                                      0    0   \n",
       "3                                                      0    0   \n",
       "4                                                      0    0   \n",
       "...                                                  ...   ..   \n",
       "12786                                                  0    0   \n",
       "12787                                                  0    0   \n",
       "12788                                                  0    0   \n",
       "12789                                                  0    0   \n",
       "12790                                                  0    0   \n",
       "\n",
       "       _yard signs posted anonymously opposing a proposed office park redevelopment in Northwest Austin  \\\n",
       "0                                                      0                                                  \n",
       "1                                                      0                                                  \n",
       "2                                                      0                                                  \n",
       "3                                                      0                                                  \n",
       "4                                                      0                                                  \n",
       "...                                                  ...                                                  \n",
       "12786                                                  0                                                  \n",
       "12787                                                  0                                                  \n",
       "12788                                                  0                                                  \n",
       "12789                                                  0                                                  \n",
       "12790                                                  0                                                  \n",
       "\n",
       "       _“Voters Guide,” League of Women Voters of the Austin Area.  \n",
       "0                                                      0            \n",
       "1                                                      0            \n",
       "2                                                      0            \n",
       "3                                                      0            \n",
       "4                                                      0            \n",
       "...                                                  ...            \n",
       "12786                                                  0            \n",
       "12787                                                  0            \n",
       "12788                                                  0            \n",
       "12789                                                  0            \n",
       "12790                                                  0            \n",
       "\n",
       "[12791 rows x 14455 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE, this, like the TF-IDF features, was found to be too large and so was dropped from the final version\n",
    "hot_coding_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label                                          Statement\n",
       "0        false  Says the Annies List political group supports ...\n",
       "1    half-true  When did the decline of coal start? It started...\n",
       "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...\n",
       "3        false  Health care reform legislation is likely to ma...\n",
       "4    half-true  The economic turnaround started at the end of ..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[['Label', 'Statement']].copy()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the functions needed for removing the features as seen below\n",
    "\n",
    "def no_of_stopwords(x):\n",
    "    sw = nltk.corpus.stopwords.words('english') \n",
    "    word_tokens = nltk.sent_tokenize(x)\n",
    "    stopwords_x = [w for w in word_tokens if w in sw]\n",
    "    return len(stopwords_x)\n",
    "\n",
    "\n",
    "def count_punc(x):\n",
    "    punctuations= string.punctuation\n",
    "    d=dict()\n",
    "    for i in punctuations:\n",
    "        d[str(i)+' count']=x.count(i)\n",
    "    count = 0\n",
    "    for i in d:\n",
    "        count += d[i]\n",
    "    return count\n",
    "\n",
    "def count_words_in_quotes(x):\n",
    "    add = re.findall(r'[\"](.*?)[\"]',x)\n",
    "    count=0\n",
    "    if add is None:\n",
    "        return 0\n",
    "    else:\n",
    "        for i in add:\n",
    "            t=i#[1:-1]\n",
    "            #print(\"t is: \", t)\n",
    "            count+=len(t) - t.count(\" \")\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First ten features\n",
    "data['body_len'] = data['Statement'].apply(lambda x: len(x) - x.count(\" \"))          # First Feature - number of letters\n",
    "data['no_of_words'] = data['Statement'].apply(lambda x: len(x.split()))              # Second Feature - number of words\n",
    "data['no_of_sent'] = data['Statement'].apply(lambda x: len(nltk.sent_tokenize(x)))   # Third Feature - number of sentences\n",
    "data['no_of_unique_words'] = data['Statement'].apply(lambda x: len(set(x.split())))  # Fourth Feature - # of unique words\n",
    "data['no_of_stopwords'] = data['Statement'].apply(lambda x: no_of_stopwords(x))      # Fifth Feature - # of stopwords\n",
    "data['avg_word_len'] = data['body_len']/data['no_of_words']                          # Sixth Feature - avg word length\n",
    "data['avg_%_stopwords'] = data['no_of_stopwords']/data['no_of_words']                # Seventh Feature - avg % being stopwords\n",
    "data['no_of_punc'] = data['Statement'].apply(lambda x: count_punc(x))                # Eight Feature - amount of punctuation\n",
    "data['words_in_quote'] = data['Statement'].apply(lambda x: count_words_in_quotes(x)) # Ninth Feature - # of words in quotes\n",
    "data['%_of_unique_words'] = data['no_of_unique_words']/data['no_of_words']           # Tenth Feature - % of words that are unique\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# This box is preparing the data to be run through the function that determines the types of words in each entry\n",
    "# for example if there are nouns or proper nouns or verbs in a particular statement.\n",
    "\n",
    "df_token = df_clean[['body_text_tokenized']]\n",
    "\n",
    "tok = df_token.to_numpy()\n",
    "\n",
    "hold = ['Hello,', \"my\", \"name\", \"is\", \"Chris\"]\n",
    "\n",
    "# Changes all of the numbers into strings\n",
    "for text in tok:\n",
    "    #print(text)\n",
    "    for w in text:\n",
    "        for word in w:\n",
    "            #print(type(word))\n",
    "            if word.isdigit():\n",
    "                num = int(word)\n",
    "entries = {}\n",
    "entries[0] = {}\n",
    "\n",
    "for i in range(0, len(tok)):\n",
    "    tagged = nltk.pos_tag([q for q in tok[i][0] if q])\n",
    "    counts = Counter(tag for word, tag in tagged)\n",
    "    entries[i] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VBZ</th>\n",
       "      <th>DT</th>\n",
       "      <th>NNS</th>\n",
       "      <th>VBP</th>\n",
       "      <th>JJ</th>\n",
       "      <th>NN</th>\n",
       "      <th>IN</th>\n",
       "      <th>WRB</th>\n",
       "      <th>VBD</th>\n",
       "      <th>PRP</th>\n",
       "      <th>...</th>\n",
       "      <th>NNP</th>\n",
       "      <th>WDT</th>\n",
       "      <th>MD</th>\n",
       "      <th>PDT</th>\n",
       "      <th>EX</th>\n",
       "      <th>RBS</th>\n",
       "      <th>$</th>\n",
       "      <th>WP$</th>\n",
       "      <th>FW</th>\n",
       "      <th>UH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12786</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12789</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12790</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12791 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       VBZ   DT  NNS  VBP   JJ    NN   IN  WRB  VBD  PRP  ...  NNP  WDT   MD  \\\n",
       "0      2.0  1.0  2.0  1.0  1.0   3.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1      0.0  1.0  0.0  0.0  2.0   7.0  3.0  2.0  5.0  1.0  ...  0.0  0.0  0.0   \n",
       "2      1.0  2.0  0.0  0.0  1.0   7.0  5.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3      1.0  0.0  1.0  0.0  2.0   6.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4      0.0  2.0  0.0  0.0  1.0   3.0  2.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
       "...    ...  ...  ...  ...  ...   ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "12786  0.0  3.0  1.0  0.0  1.0   4.0  6.0  0.0  2.0  1.0  ...  0.0  0.0  0.0   \n",
       "12787  2.0  0.0  2.0  0.0  0.0   2.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "12788  0.0  1.0  1.0  1.0  1.0   6.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "12789  2.0  4.0  1.0  2.0  3.0  10.0  1.0  0.0  0.0  2.0  ...  0.0  1.0  0.0   \n",
       "12790  2.0  3.0  0.0  0.0  2.0   8.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "       PDT   EX  RBS    $  WP$   FW   UH  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "12786  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12787  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12788  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12789  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12790  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[12791 rows x 34 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_structure = pd.DataFrame.from_dict(entries) # make a new dataframe\n",
    "# swap the rows and columns\n",
    "word_structure = word_structure.T\n",
    "# replace NAN\n",
    "word_structure = word_structure.fillna(0.0)\n",
    "\n",
    "word_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features 11 - 20\n",
    "# Second ten features\n",
    "data['no_of_numerical'] = data['Statement'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))  # 11th feature amount of numerical values\n",
    "data['upper_case_words'] = data['Statement'].apply(lambda x: len([x for x in x.split() if x.isupper()])) # 12th feature amount of uppercase words\n",
    "data['avg_sentence_length'] = data['no_of_words']/data['no_of_sent']                                     # 13th feature average sentence length\n",
    "data['no_of_nouns'] = word_structure['NN'] + word_structure['NNS']                                       # 14th feature amount of nouns in entry\n",
    "data['proper_nouns'] = word_structure['NNP'] + word_structure['NNPS']                                    # 15th feature number of proper nouns\n",
    "data['no_of_base_verbs'] = word_structure['VB']                                                          # 16th feature number of base verbs\n",
    "data['past_tense_verbs'] = word_structure['VBD']                                                         # 17th feature number of past tense verbs\n",
    "data['verb_participle'] = word_structure['VBG'] + word_structure['VBN']                                  # 18th feature number of participle verbs\n",
    "data['no_of_adj'] = word_structure['JJ'] + word_structure['JJR'] + word_structure['JJS']                 # 19th feature number of adjectives\n",
    "data['personal_pronouns'] = word_structure['PRP']                                                        # 20th feature number of personal pronouns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features 21 - 30\n",
    "# Third ten features\n",
    "data['no_of_particles'] = word_structure['RP']                                               # 21st feature, number of particles\n",
    "data['no_of_prepositions'] = word_structure['IN']                                            # 22nd feature, number of prepositions\n",
    "data['no_of_foreign_words'] = word_structure['FW']                                           # 23rd feature, number of foreign words \n",
    "data['no_of_adverbs'] = word_structure['RB'] + word_structure['RBR'] + word_structure['RBS'] # 24th feature, number of adverbs\n",
    "data['pos_pronouns'] = word_structure['PRP$']                                                # 25th feature, number of possessive pronouns\n",
    "data['no_of_numerals'] = word_structure['CD']                                                # 26th feature, number of numbers\n",
    "data['no_of_interjections'] = word_structure['UH']                                           # 27th feature, number of interjections\n",
    "data['no_of_determiners'] = word_structure['DT']                                             # 28th feature, number of determiners\n",
    "data['no_of_predeterminers'] = word_structure['PDT']                                         # 29th feature, number of pre-determiners\n",
    "# 30th feature, number of wh- question words\n",
    "data['WH_questions'] = word_structure['WDT'] + word_structure['WP'] + word_structure['WP$'] + word_structure['WRB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features 31 - 40\n",
    "# Fourth ten features\n",
    "data['no_long_words'] = data['Statement'].apply(lambda x: len([x for x in x.split()if x and len(x) > 6]))   # feature 31, number of \"long\" words\n",
    "data['no_short_words'] = data['Statement'].apply(lambda x: len([x for x in x.split()if x and len(x) <= 6])) # feature 32, number of \"short\" words\n",
    "data['no_very_short_words'] = data['Statement'].apply(lambda x: len([x for x in x.split()if x and len(x) < 3])) # feature 33, number of \"very short\" words\n",
    "data['no_very_long_words'] = data['Statement'].apply(lambda x: len([x for x in x.split()if x and len(x) > 9])) # feature 34, number of \"very long\" words\n",
    "data['percent_long_words'] = data['no_long_words']/data['no_of_words']                                         # feature 35, % of long words\n",
    "data['percent_very_long_words'] = data['no_very_long_words']/data['no_of_words']                               # feature 36, % very long words\n",
    "data['percent_very_short_words'] = data['no_very_short_words']/data['no_of_words']                             # feature 37, % very short words\n",
    "data['avg_long_word_per_sentence'] = data['no_long_words']/data['no_of_sent']                                  # feature 38, number of long words in sentences\n",
    "data['%_nouns'] = data['no_of_nouns']/data['no_of_words']                                                      # feature 39, % that is nouns\n",
    "data['%_adjectives'] = data['no_of_adj']/data['no_of_words']                                                   # feature 40, % that is adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>body_len</th>\n",
       "      <th>no_of_words</th>\n",
       "      <th>no_of_sent</th>\n",
       "      <th>no_of_unique_words</th>\n",
       "      <th>no_of_stopwords</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>avg_%_stopwords</th>\n",
       "      <th>no_of_punc</th>\n",
       "      <th>...</th>\n",
       "      <th>%_particles</th>\n",
       "      <th>%_prepositions</th>\n",
       "      <th>%_adverbs</th>\n",
       "      <th>%_WH_questions</th>\n",
       "      <th>%_verbs</th>\n",
       "      <th>%_personal_pronouns</th>\n",
       "      <th>%_proper_nouns</th>\n",
       "      <th>%_numerals</th>\n",
       "      <th>%_in_quotes</th>\n",
       "      <th>%_determiners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>72</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>118</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>87</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>4.578947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.684211</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12786</th>\n",
       "      <td>half-true</td>\n",
       "      <td>For the first time in more than a decade, impo...</td>\n",
       "      <td>85</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Says Donald Trump has bankrupted his companies...</td>\n",
       "      <td>69</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>true</td>\n",
       "      <td>John McCain and George Bush have \"absolutely n...</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12789</th>\n",
       "      <td>false</td>\n",
       "      <td>A new poll shows 62 percent support the presid...</td>\n",
       "      <td>164</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4.969697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12790</th>\n",
       "      <td>barely-true</td>\n",
       "      <td>No one claims the report vindicating New Jerse...</td>\n",
       "      <td>88</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>5.176471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12791 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Label                                          Statement  \\\n",
       "0            false  Says the Annies List political group supports ...   \n",
       "1        half-true  When did the decline of coal start? It started...   \n",
       "2      mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3            false  Health care reform legislation is likely to ma...   \n",
       "4        half-true  The economic turnaround started at the end of ...   \n",
       "...            ...                                                ...   \n",
       "12786    half-true  For the first time in more than a decade, impo...   \n",
       "12787  mostly-true  Says Donald Trump has bankrupted his companies...   \n",
       "12788         true  John McCain and George Bush have \"absolutely n...   \n",
       "12789        false  A new poll shows 62 percent support the presid...   \n",
       "12790  barely-true  No one claims the report vindicating New Jerse...   \n",
       "\n",
       "       body_len  no_of_words  no_of_sent  no_of_unique_words  no_of_stopwords  \\\n",
       "0            72           11           1                  11                0   \n",
       "1           118           24           2                  23                0   \n",
       "2            87           19           1                  18                0   \n",
       "3            67           12           1                  12                0   \n",
       "4            45           10           1                  10                0   \n",
       "...         ...          ...         ...                 ...              ...   \n",
       "12786        85           20           1                  19                0   \n",
       "12787        69           14           1                  13                0   \n",
       "12788        68           13           1                  13                0   \n",
       "12789       164           33           2                  29                0   \n",
       "12790        88           17           2                  16                0   \n",
       "\n",
       "       avg_word_len  avg_%_stopwords  no_of_punc  ...  %_particles  \\\n",
       "0          6.545455              0.0           2  ...     0.000000   \n",
       "1          4.916667              0.0           5  ...     0.041667   \n",
       "2          4.578947              0.0           3  ...     0.000000   \n",
       "3          5.583333              0.0           1  ...     0.000000   \n",
       "4          4.500000              0.0           1  ...     0.000000   \n",
       "...             ...              ...         ...  ...          ...   \n",
       "12786      4.250000              0.0           4  ...     0.000000   \n",
       "12787      4.928571              0.0           2  ...     0.000000   \n",
       "12788      5.230769              0.0           3  ...     0.000000   \n",
       "12789      4.969697              0.0           6  ...     0.000000   \n",
       "12790      5.176471              0.0           2  ...     0.000000   \n",
       "\n",
       "       %_prepositions  %_adverbs  %_WH_questions   %_verbs  \\\n",
       "0            0.090909   0.000000        0.000000  0.000000   \n",
       "1            0.125000   0.000000        0.083333  0.250000   \n",
       "2            0.263158   0.000000        0.000000  0.052632   \n",
       "3            0.000000   0.000000        0.000000  0.083333   \n",
       "4            0.200000   0.000000        0.000000  0.100000   \n",
       "...               ...        ...             ...       ...   \n",
       "12786        0.300000   0.000000        0.000000  0.100000   \n",
       "12787        0.000000   0.285714        0.000000  0.000000   \n",
       "12788        0.076923   0.076923        0.000000  0.000000   \n",
       "12789        0.030303   0.000000        0.030303  0.030303   \n",
       "12790        0.058824   0.000000        0.000000  0.000000   \n",
       "\n",
       "       %_personal_pronouns  %_proper_nouns  %_numerals  %_in_quotes  \\\n",
       "0                 0.000000             0.0    0.000000     0.000000   \n",
       "1                 0.041667             0.0    0.000000     0.000000   \n",
       "2                 0.000000             0.0    0.000000     2.684211   \n",
       "3                 0.000000             0.0    0.000000     0.000000   \n",
       "4                 0.000000             0.0    0.000000     0.000000   \n",
       "...                    ...             ...         ...          ...   \n",
       "12786             0.050000             0.0    0.000000     0.000000   \n",
       "12787             0.000000             0.0    0.071429     0.000000   \n",
       "12788             0.000000             0.0    0.000000     3.000000   \n",
       "12789             0.060606             0.0    0.030303     0.000000   \n",
       "12790             0.000000             0.0    0.000000     0.000000   \n",
       "\n",
       "       %_determiners  \n",
       "0           0.090909  \n",
       "1           0.041667  \n",
       "2           0.105263  \n",
       "3           0.000000  \n",
       "4           0.200000  \n",
       "...              ...  \n",
       "12786       0.150000  \n",
       "12787       0.000000  \n",
       "12788       0.076923  \n",
       "12789       0.121212  \n",
       "12790       0.176471  \n",
       "\n",
       "[12791 rows x 52 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features 41 - 50\n",
    "# Fifth ten features\n",
    "data['%_particles'] = data['no_of_particles']/data['no_of_words']                               # feature 41, % that is particles\n",
    "data['%_prepositions'] = data['no_of_prepositions']/data['no_of_words']                         # feature 42, % that is prepositions\n",
    "data['%_adverbs'] = data['no_of_adverbs']/data['no_of_words']                                   # feature 43, % that is adverbs\n",
    "data['%_WH_questions'] = data['WH_questions']/data['no_of_words']                               # feature 44, % that is WH questions\n",
    "data['%_verbs'] = (data['no_of_base_verbs'] + data['past_tense_verbs'])/data['no_of_words']     # feature 45, % that are verbs\n",
    "data['%_personal_pronouns'] = data['personal_pronouns']/data['no_of_words']                     # feature 46, % that are personal pronouns\n",
    "data['%_proper_nouns'] = data['proper_nouns']/data['no_of_words']                               # feature 47, % that are proper pronouns\n",
    "data['%_numerals'] = data['no_of_numerals']/data['no_of_words']                                 # feature 48, % that are numbers\n",
    "data['%_in_quotes'] = data['words_in_quote']/data['no_of_words']                                # feature 49, % of words that are in quotes\n",
    "data['%_determiners'] = data['no_of_determiners']/data['no_of_words']                           # feature 50, % of words that are determiners\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Data Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section was done as a replacement for the hot_coding_data section used previously\n",
    "\n",
    "data_hold = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace republican with 2, Democrat with 1, and none/independent with 8\n",
    "# Replace third party with 3\n",
    "# Replace official with 4, organization with 5\n",
    "# Replace journalist/journalist entertainers with 6\n",
    "# Replace other with 7\n",
    "\n",
    "data_hold['Party'] = data_hold['Party'].replace(['republican', 'democrat','none', 'independent'],[2, 1, 8, 8])\n",
    "data_hold['Party'] = data_hold['Party'].replace(['libertarian', 'green', 'Moderate', 'democratic-farmer-labor',\n",
    "                                                 'ocean-state-tea-party-action', 'constitution-party',\n",
    "                                                'labor-leader', 'tea-party-member'], 3)\n",
    "data_hold['Party'] = data_hold['Party'].replace(['state-official', 'education-official', 'organization', \n",
    "                                                 'government-body'],[4,4,5,4])\n",
    "data_hold['Party'] = data_hold['Party'].replace(['columnist', 'talk-show-host', 'newsmaker', 'journalist'],6)\n",
    "data_hold['Party'] = data_hold['Party'].replace(['activist', 'business-leader', 'liberal-party-canada',\n",
    "                                                 'county-commissioner'],7)\n",
    "extracted_col = data_hold['Party']\n",
    "data = data.join(extracted_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add history of the speaker to the features\n",
    "# Barely_True_History has only integers, 30 unique values\n",
    "# False_History has only integers, 30 unique values\n",
    "# Half_True_History has only integers, 29 unique values\n",
    "# Mostly_True_History has only integers, 27 unique values\n",
    "# Pants_On_Fire_History has only integers, 20 unique values\n",
    "\n",
    "extracted_cols = data_hold[['Barely_True_History', 'False_History', 'Half_True_History', \n",
    "                            'Mostly_True_History', 'Pants_On_Fire_History']]\n",
    "data=data.join(extracted_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below features were removed as they caused overfitting of the Bi-LSTM network\n",
    "\n",
    "# data['Speaker'] = pd.factorize(data_hold.Speaker)[0] + 1 # 3310 unique entries\n",
    "# data['State'] = pd.factorize(data_hold.State)[0] + 1 # 86 unique entries (at least)\n",
    "\n",
    "# data_hold['Subject'] = data_hold['Subject(s)']\n",
    "# # data_hold = data_hold.drop(['Subject(s)'])\n",
    "# data['Subject'] = pd.factorize(data_hold['Subject'])[0] + 1 # 4535 unique entries\n",
    "\n",
    "# data['Speaker_Job'] = pd.factorize(data_hold['Speaker_Job'])[0] + 1 # 1356 unique entries\n",
    "# data['Context'] = pd.factorize(data_hold['Context'])[0] + 1 # 5143 unique entries\n",
    "# print(data_hold['Speaker'].nunique())\n",
    "\n",
    "# print(\"Speaker: \",data['Speaker'].nunique())\n",
    "# print(\"State: \",data['State'].nunique())\n",
    "# print(\"Subject: \",data['Subject'].nunique())\n",
    "# print(\"Speaker_job: \",data['Speaker_Job'].nunique())\n",
    "# print(\"Context: \",data['Context'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>body_len</th>\n",
       "      <th>no_of_words</th>\n",
       "      <th>no_of_sent</th>\n",
       "      <th>no_of_unique_words</th>\n",
       "      <th>no_of_stopwords</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>avg_%_stopwords</th>\n",
       "      <th>no_of_punc</th>\n",
       "      <th>...</th>\n",
       "      <th>%_proper_nouns</th>\n",
       "      <th>%_numerals</th>\n",
       "      <th>%_in_quotes</th>\n",
       "      <th>%_determiners</th>\n",
       "      <th>Party</th>\n",
       "      <th>Barely_True_History</th>\n",
       "      <th>False_History</th>\n",
       "      <th>Half_True_History</th>\n",
       "      <th>Mostly_True_History</th>\n",
       "      <th>Pants_On_Fire_History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>72</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>118</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>87</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>4.578947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.684211</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12786</th>\n",
       "      <td>half-true</td>\n",
       "      <td>For the first time in more than a decade, impo...</td>\n",
       "      <td>85</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Says Donald Trump has bankrupted his companies...</td>\n",
       "      <td>69</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>true</td>\n",
       "      <td>John McCain and George Bush have \"absolutely n...</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12789</th>\n",
       "      <td>false</td>\n",
       "      <td>A new poll shows 62 percent support the presid...</td>\n",
       "      <td>164</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4.969697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12790</th>\n",
       "      <td>barely-true</td>\n",
       "      <td>No one claims the report vindicating New Jerse...</td>\n",
       "      <td>88</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>5.176471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12791 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Label                                          Statement  \\\n",
       "0            false  Says the Annies List political group supports ...   \n",
       "1        half-true  When did the decline of coal start? It started...   \n",
       "2      mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3            false  Health care reform legislation is likely to ma...   \n",
       "4        half-true  The economic turnaround started at the end of ...   \n",
       "...            ...                                                ...   \n",
       "12786    half-true  For the first time in more than a decade, impo...   \n",
       "12787  mostly-true  Says Donald Trump has bankrupted his companies...   \n",
       "12788         true  John McCain and George Bush have \"absolutely n...   \n",
       "12789        false  A new poll shows 62 percent support the presid...   \n",
       "12790  barely-true  No one claims the report vindicating New Jerse...   \n",
       "\n",
       "       body_len  no_of_words  no_of_sent  no_of_unique_words  no_of_stopwords  \\\n",
       "0            72           11           1                  11                0   \n",
       "1           118           24           2                  23                0   \n",
       "2            87           19           1                  18                0   \n",
       "3            67           12           1                  12                0   \n",
       "4            45           10           1                  10                0   \n",
       "...         ...          ...         ...                 ...              ...   \n",
       "12786        85           20           1                  19                0   \n",
       "12787        69           14           1                  13                0   \n",
       "12788        68           13           1                  13                0   \n",
       "12789       164           33           2                  29                0   \n",
       "12790        88           17           2                  16                0   \n",
       "\n",
       "       avg_word_len  avg_%_stopwords  no_of_punc  ...  %_proper_nouns  \\\n",
       "0          6.545455              0.0           2  ...             0.0   \n",
       "1          4.916667              0.0           5  ...             0.0   \n",
       "2          4.578947              0.0           3  ...             0.0   \n",
       "3          5.583333              0.0           1  ...             0.0   \n",
       "4          4.500000              0.0           1  ...             0.0   \n",
       "...             ...              ...         ...  ...             ...   \n",
       "12786      4.250000              0.0           4  ...             0.0   \n",
       "12787      4.928571              0.0           2  ...             0.0   \n",
       "12788      5.230769              0.0           3  ...             0.0   \n",
       "12789      4.969697              0.0           6  ...             0.0   \n",
       "12790      5.176471              0.0           2  ...             0.0   \n",
       "\n",
       "       %_numerals  %_in_quotes  %_determiners  Party  Barely_True_History  \\\n",
       "0        0.000000     0.000000       0.090909    2.0                  0.0   \n",
       "1        0.000000     0.000000       0.041667    1.0                  0.0   \n",
       "2        0.000000     2.684211       0.105263    1.0                 70.0   \n",
       "3        0.000000     0.000000       0.000000    8.0                  7.0   \n",
       "4        0.000000     0.000000       0.200000    1.0                 15.0   \n",
       "...           ...          ...            ...    ...                  ...   \n",
       "12786    0.000000     0.000000       0.150000    1.0                 70.0   \n",
       "12787    0.071429     0.000000       0.000000    1.0                 40.0   \n",
       "12788    0.000000     3.000000       0.076923    8.0                  0.0   \n",
       "12789    0.030303     0.000000       0.121212    8.0                  1.0   \n",
       "12790    0.000000     0.000000       0.176471    2.0                  9.0   \n",
       "\n",
       "       False_History  Half_True_History  Mostly_True_History  \\\n",
       "0                1.0                0.0                  0.0   \n",
       "1                0.0                1.0                  1.0   \n",
       "2               71.0              160.0                163.0   \n",
       "3               19.0                3.0                  5.0   \n",
       "4                9.0               20.0                 19.0   \n",
       "...              ...                ...                  ...   \n",
       "12786           71.0              160.0                163.0   \n",
       "12787           29.0               69.0                 76.0   \n",
       "12788            1.0                0.0                  2.0   \n",
       "12789            4.0                4.0                  1.0   \n",
       "12790           11.0               10.0                  7.0   \n",
       "\n",
       "       Pants_On_Fire_History  \n",
       "0                        0.0  \n",
       "1                        0.0  \n",
       "2                        9.0  \n",
       "3                       44.0  \n",
       "4                        2.0  \n",
       "...                      ...  \n",
       "12786                    9.0  \n",
       "12787                    7.0  \n",
       "12788                    0.0  \n",
       "12789                    0.0  \n",
       "12790                    3.0  \n",
       "\n",
       "[12791 rows x 58 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the random forest imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "data_train = data.drop(columns = ['Label', 'Statement'])\n",
    "\n",
    "df_features = data_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the datasets back into training, testing and validation\n",
    "df_1 = df_features.iloc[:10240,:]\n",
    "df_2 = df_features.iloc[10240:,:]\n",
    "\n",
    "testing = df_2.iloc[:1267,:]\n",
    "validate = df_2.iloc[1267:,:]\n",
    "testing = testing.reset_index()\n",
    "validate = validate.reset_index()\n",
    "\n",
    "\n",
    "testing = testing.drop(columns = ['index'])\n",
    "validate = validate.drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with 100 trees\n",
    "model = RandomForestClassifier(n_estimators=100, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features='sqrt')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on training data\n",
    "model.fit(df_1, train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Half_True_History</th>\n",
       "      <td>0.056916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mostly_True_History</th>\n",
       "      <td>0.056082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False_History</th>\n",
       "      <td>0.054658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barely_True_History</th>\n",
       "      <td>0.049035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pants_On_Fire_History</th>\n",
       "      <td>0.036213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_word_len</th>\n",
       "      <td>0.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_nouns</th>\n",
       "      <td>0.033407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_long_words</th>\n",
       "      <td>0.032226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_len</th>\n",
       "      <td>0.032203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_very_short_words</th>\n",
       "      <td>0.032098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_prepositions</th>\n",
       "      <td>0.031495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_determiners</th>\n",
       "      <td>0.028578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_adjectives</th>\n",
       "      <td>0.028551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_verbs</th>\n",
       "      <td>0.025432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_very_long_words</th>\n",
       "      <td>0.024947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_short_words</th>\n",
       "      <td>0.023440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <td>0.023327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_unique_words</th>\n",
       "      <td>0.021964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_words</th>\n",
       "      <td>0.021575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_long_word_per_sentence</th>\n",
       "      <td>0.020400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            importance\n",
       "Half_True_History             0.056916\n",
       "Mostly_True_History           0.056082\n",
       "False_History                 0.054658\n",
       "Barely_True_History           0.049035\n",
       "Pants_On_Fire_History         0.036213\n",
       "avg_word_len                  0.035700\n",
       "%_nouns                       0.033407\n",
       "percent_long_words            0.032226\n",
       "body_len                      0.032203\n",
       "percent_very_short_words      0.032098\n",
       "%_prepositions                0.031495\n",
       "%_determiners                 0.028578\n",
       "%_adjectives                  0.028551\n",
       "%_verbs                       0.025432\n",
       "percent_very_long_words       0.024947\n",
       "no_short_words                0.023440\n",
       "avg_sentence_length           0.023327\n",
       "no_of_unique_words            0.021964\n",
       "no_of_words                   0.021575\n",
       "avg_long_word_per_sentence    0.020400"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the most important features, and print them out in descending order of importance.\n",
    "\n",
    "feature_importances = pd.DataFrame(model.feature_importances_, index = df_1.columns,  \n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(max_features='sqrt'),\n",
       "                threshold=0.001)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin feature selection\n",
    "rf_model = SelectFromModel(model, threshold = 0.001)\n",
    "rf_model.fit(df_1, train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data to create a new dataset containing only the most important features\n",
    "# Note: We have to apply the transform to both the training X and test X data.\n",
    "rf_2_train = rf_model.transform(df_1)\n",
    "rf_2_test = rf_model.transform(testing)\n",
    "rf_2_valid = rf_model.transform(validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# function for running through the random forest model several times\n",
    "def forest():\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1) # n_jobs makes it go fast, random state increases the accuracy\n",
    "    \n",
    "    rf.fit(rf_2_train,train['Label'])\n",
    "    \n",
    "    # Actual class predictions\n",
    "    rf_model_t = rf.predict(rf_2_test)\n",
    "    rf_model_v = rf.predict(rf_2_valid)\n",
    "\n",
    "    # View accuracy score\n",
    "    rf_test_sc = accuracy_score(test['Label'], rf_model_t)\n",
    "    rf_valid_sc = accuracy_score(valid['Label'], rf_model_v)\n",
    "    \n",
    "    return rf_test_sc, rf_valid_sc\n",
    "\n",
    "# function for getting the average of several numbers\n",
    "def cal_average(num):\n",
    "    sum_num = 0\n",
    "    for t in num:\n",
    "        sum_num = sum_num + t           \n",
    "    if len(num) > 0:\n",
    "        avg = sum_num / len(num)\n",
    "    else: \n",
    "        avg = 0\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is:  0.44672454617206003\n",
      "Valid score is:  0.4369158878504673\n",
      "The non selected score is:  0.4230465666929755\n"
     ]
    }
   ],
   "source": [
    "# Train the random forest classifier 10 times and get the average score for both the test and valid data set.\n",
    "\n",
    "features_normal_t = []\n",
    "features_normal_v = []\n",
    "\n",
    "for i in range(10):\n",
    "    test_sc, valid_sc = forest()\n",
    "    features_normal_t.append(test_sc)\n",
    "    features_normal_v.append(valid_sc)\n",
    "\n",
    "normal_t = cal_average(features_normal_t)\n",
    "normal_v = cal_average(features_normal_v)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "\n",
    "rf_model = rf_model.fit(df_1, train['Label'])\n",
    "\n",
    "# predictions for un-selected features.\n",
    "rf_model_t = rf_model.predict(testing)\n",
    "\n",
    "# View accuracy score\n",
    "rf_test_sc = accuracy_score(test['Label'], rf_model_t)\n",
    "\n",
    "print(\"Test score is: \", normal_t)\n",
    "print(\"Valid score is: \", normal_v)\n",
    "print(\"The non selected score is: \", rf_test_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Bi-LSTM code: https://medium.com/analytics-vidhya/building-a-text-classification-model-using-bilstm-c0548ace26f2\n"
     ]
    }
   ],
   "source": [
    "# The links that will be used\n",
    "\n",
    "print(\"For the Bi-LSTM code: https://medium.com/analytics-vidhya/building-a-text-classification-model-using-bilstm-c0548ace26f2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from keras.layers import Dropout, Dense, Embedding, LSTM, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "import logging\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Import the tools we will need from keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize and fit the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train['Statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will build the Bi-LSTM model\n",
    "def bilstm_initialize(nclasses, dropout=0.5, hidden_layer = 3, lstm_node = 32):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(tokenizer.index_word)+1, 32))\n",
    "    for i in range(0,hidden_layer):\n",
    "        # Add a bidirectional lstm layer\n",
    "        model.add(Bidirectional(LSTM(lstm_node, return_sequences=True, recurrent_dropout=0.2)))\n",
    "        # Add a dropout layer after each lstm layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Bidirectional(LSTM(lstm_node, recurrent_dropout=0.2)))\n",
    "    model.add(Dropout(dropout))\n",
    "    # Add the fully connected layer with 256 nurons and relu activation\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    # Add the output layer with softmax activation since we have 6 classes\n",
    "    model.add(Dense(nclasses, activation='softmax'))\n",
    "    # Compile the model using sparse_categorical_crossentropy\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the score of the Neural Network model\n",
    "\n",
    "def get_eval_report(labels, preds):\n",
    "    mcc = matthews_corrcoef(labels, preds)\n",
    "    print(confusion_matrix(labels, preds))\n",
    "    print(confusion_matrix(labels, preds).ravel())\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    precision = (tp)/(tp+fp)\n",
    "    recall = (tp)/(tp+fn)\n",
    "    f1 = (2*(precision*recall))/(precision+recall)\n",
    "    return {\n",
    "        \"mcc\": mcc,\n",
    "        \"true positive\": tp,\n",
    "        \"true negative\": tn,\n",
    "        \"false positive\": fp,\n",
    "        \"false negative\": fn,\n",
    "        \"pricision\" : precision,\n",
    "        \"recall\" : recall,\n",
    "        \"F1\" : f1,\n",
    "        \"accuracy\": (tp+tn)/(tp+tn+fp+fn)\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_metrics(labels, preds):\n",
    "    assert len(preds) == len(labels)\n",
    "    return get_eval_report(labels, preds)\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 32)          397088    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 64)          16640     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 64)          24832     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, None, 64)          24832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 506,406\n",
      "Trainable params: 506,406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model_bilstm = bilstm_initialize(6)\n",
    "model_bilstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the categorical values numbers\n",
    "y_train = train[['Label']]\n",
    "y_test = test[['Label']]\n",
    "y_valid = valid[['Label']]\n",
    "\n",
    "\n",
    "# replace the y_training values\n",
    "y_train = y_train.replace('false', 0)\n",
    "y_train = y_train.replace('half-true', 1)\n",
    "y_train = y_train.replace('mostly-true', 2)\n",
    "y_train = y_train.replace('true', 3)\n",
    "y_train = y_train.replace('barely-true', 4)\n",
    "y_train = y_train.replace('pants-fire', 5)\n",
    "\n",
    "# replace the y_testing values\n",
    "y_test = y_test.replace('false', 0)\n",
    "y_test = y_test.replace('half-true', 1)\n",
    "y_test = y_test.replace('mostly-true', 2)\n",
    "y_test = y_test.replace('true', 3)\n",
    "y_test = y_test.replace('barely-true', 4)\n",
    "y_test = y_test.replace('pants-fire', 5)\n",
    "\n",
    "# replace the y_testing values\n",
    "y_valid = y_valid.replace('false', 0)\n",
    "y_valid = y_valid.replace('half-true', 1)\n",
    "y_valid = y_valid.replace('mostly-true', 2)\n",
    "y_valid = y_valid.replace('true', 3)\n",
    "y_valid = y_valid.replace('barely-true', 4)\n",
    "y_valid = y_valid.replace('pants-fire', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "80/80 [==============================] - 18s 136ms/step - loss: 1.7705 - accuracy: 0.1931 - val_loss: 1.7646 - val_accuracy: 0.1955\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.7550 - accuracy: 0.2089 - val_loss: 1.7345 - val_accuracy: 0.2126\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 1.7380 - accuracy: 0.2182 - val_loss: 1.7173 - val_accuracy: 0.2204\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 1.7272 - accuracy: 0.2159 - val_loss: 1.7165 - val_accuracy: 0.2095\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 1.7177 - accuracy: 0.2313 - val_loss: 1.6857 - val_accuracy: 0.2391\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.6603 - accuracy: 0.2713 - val_loss: 1.5756 - val_accuracy: 0.2936\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.5679 - accuracy: 0.3251 - val_loss: 1.4288 - val_accuracy: 0.3925\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 10s 122ms/step - loss: 1.4586 - accuracy: 0.3707 - val_loss: 1.4011 - val_accuracy: 0.3995\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.4151 - accuracy: 0.3886 - val_loss: 1.3811 - val_accuracy: 0.3886\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 1.4121 - accuracy: 0.3955 - val_loss: 1.3691 - val_accuracy: 0.4073\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 10s 122ms/step - loss: 1.4013 - accuracy: 0.3995 - val_loss: 1.3712 - val_accuracy: 0.3933\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 1.3884 - accuracy: 0.4033 - val_loss: 1.3668 - val_accuracy: 0.3956\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 1.3697 - accuracy: 0.4134 - val_loss: 1.3640 - val_accuracy: 0.3995\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 1.3790 - accuracy: 0.4187 - val_loss: 1.3657 - val_accuracy: 0.3941\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 1.3655 - accuracy: 0.4197 - val_loss: 1.3593 - val_accuracy: 0.3972\n"
     ]
    }
   ],
   "source": [
    "# Train the Bi-LSTM\n",
    "history = model_bilstm.fit(rf_2_train, y_train, \n",
    "                    batch_size=128, epochs=15,\n",
    "                    validation_data=(rf_2_valid, y_valid)) # test its accuracy with the validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the resulting accuracy and loss over the epochs\n",
    "plot_graphs(history, 'accuracy')\n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluating Model ... \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.51      0.41       249\n",
      "           1       0.30      0.45      0.36       265\n",
      "           2       0.38      0.45      0.41       241\n",
      "           3       0.91      0.15      0.26       208\n",
      "           4       0.72      0.20      0.32       212\n",
      "           5       0.46      0.64      0.53        92\n",
      "\n",
      "    accuracy                           0.38      1267\n",
      "   macro avg       0.52      0.40      0.38      1267\n",
      "weighted avg       0.51      0.38      0.37      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"\\n Evaluating Model ... \\n\")\n",
    "predicted = model_bilstm.predict_classes(rf_2_test)\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 28ms/step - loss: 1.3842 - accuracy: 0.3844\n",
      "Bi-LSTM :\n",
      "  Loss: 1.384\n",
      "  Accuracy: 0.384\n"
     ]
    }
   ],
   "source": [
    "# Determine its accuracy\n",
    "accr = model_bilstm.evaluate(rf_2_test,y_test)\n",
    "print('Bi-LSTM :\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "kModel = KerasClassifier(build_fn = lambda: bilstm_initialize(6), epochs=15, batch_size=128, verbose=1)\n",
    "kModel._estimator_type = \"classifier\"\n",
    "\n",
    "# Create a new random forest classifier for the most important features\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score\n",
    "\n",
    "def voting_class(nn, forest):\n",
    "    vote_test = VotingClassifier(\n",
    "     estimators=[('Bi-LSTM', kModel), ('rf', rf)],\n",
    "     voting='soft', weights=[nn,forest], flatten_transform=True)\n",
    "    \n",
    "    t = test['Label']\n",
    "    v = valid['Label']\n",
    "    \n",
    "    vote_test = vote_test.fit(rf_2_train, train[\"Label\"])\n",
    "    \n",
    "    vote_pred = vote_test.predict(rf_2_test)\n",
    "    \n",
    "    # get accuracy\n",
    "    vote_sc = accuracy_score(t, vote_pred)\n",
    "    \n",
    "    # get precision\n",
    "    vote_pre = precision_score(t, vote_pred, average=None)\n",
    "    \n",
    "    # get recall\n",
    "    vote_rec = recall_score(t, vote_pred, average=None)\n",
    "\n",
    "    return vote_sc, vote_pre, vote_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is turn:  1\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 109ms/step - loss: 1.7689 - accuracy: 0.2022\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7544 - accuracy: 0.2036\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7272 - accuracy: 0.2198\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7245 - accuracy: 0.2196\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7192 - accuracy: 0.2251\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7023 - accuracy: 0.2421\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.6263 - accuracy: 0.2837\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4993 - accuracy: 0.3608\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4440 - accuracy: 0.3725\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4095 - accuracy: 0.3898\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4125 - accuracy: 0.3985\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3861 - accuracy: 0.4043\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3952 - accuracy: 0.4061\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3864 - accuracy: 0.4059\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3665 - accuracy: 0.4132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 29ms/step\n",
      "[0.4530386740331492]\n",
      "This is turn:  2\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 109ms/step - loss: 1.7682 - accuracy: 0.1958\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7519 - accuracy: 0.1995\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7352 - accuracy: 0.2117\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7237 - accuracy: 0.2176\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7225 - accuracy: 0.2267\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7089 - accuracy: 0.2364\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.6302 - accuracy: 0.2857\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.5418 - accuracy: 0.3457\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4594 - accuracy: 0.3758\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4227 - accuracy: 0.3886\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4086 - accuracy: 0.4008\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3907 - accuracy: 0.4088\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3783 - accuracy: 0.4111\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4061 - accuracy: 0.4037\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3734 - accuracy: 0.4155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 28ms/step\n",
      "[0.4530386740331492, 0.4514601420678769]\n",
      "This is turn:  3\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 107ms/step - loss: 1.7688 - accuracy: 0.1996\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7553 - accuracy: 0.1974\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7331 - accuracy: 0.2153\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7250 - accuracy: 0.2228\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7102 - accuracy: 0.2282\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6459 - accuracy: 0.2702\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.5197 - accuracy: 0.3320\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4431 - accuracy: 0.3685\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4297 - accuracy: 0.3904\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4034 - accuracy: 0.3980\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3880 - accuracy: 0.4022\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3842 - accuracy: 0.4057\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3735 - accuracy: 0.4133\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3816 - accuracy: 0.4037\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3641 - accuracy: 0.4178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 27ms/step\n",
      "[0.4530386740331492, 0.4514601420678769, 0.4483030781373323]\n",
      "This is turn:  4\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 108ms/step - loss: 1.7709 - accuracy: 0.1978\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7570 - accuracy: 0.2033\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7424 - accuracy: 0.2141\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7265 - accuracy: 0.2144\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7145 - accuracy: 0.2248\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.6642 - accuracy: 0.2547\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.5508 - accuracy: 0.3310\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4694 - accuracy: 0.3657\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4307 - accuracy: 0.3804\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4214 - accuracy: 0.3836\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3957 - accuracy: 0.4007\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3907 - accuracy: 0.4062\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3832 - accuracy: 0.4026\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3917 - accuracy: 0.4049\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3679 - accuracy: 0.4154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 27ms/step\n",
      "[0.4530386740331492, 0.4514601420678769, 0.4483030781373323, 0.44593528018942385]\n",
      "This is turn:  5\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 106ms/step - loss: 1.7696 - accuracy: 0.2043\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7565 - accuracy: 0.2049\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.7308 - accuracy: 0.2178\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7293 - accuracy: 0.2163\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7280 - accuracy: 0.2133\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.7045 - accuracy: 0.2464\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.6232 - accuracy: 0.2968\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.4762 - accuracy: 0.3703\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.4260 - accuracy: 0.3916\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.4084 - accuracy: 0.4021\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3998 - accuracy: 0.4049\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3876 - accuracy: 0.4128\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3891 - accuracy: 0.4127\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.3661 - accuracy: 0.4221\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.3766 - accuracy: 0.4202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 25ms/step\n",
      "[0.4530386740331492, 0.4514601420678769, 0.4483030781373323, 0.44593528018942385, 0.44672454617206]\n",
      "This is turn:  6\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 109ms/step - loss: 1.7712 - accuracy: 0.1955\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7493 - accuracy: 0.2044\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7315 - accuracy: 0.2147\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7250 - accuracy: 0.2218\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7247 - accuracy: 0.2193\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.7126 - accuracy: 0.2396\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.6706 - accuracy: 0.2703\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 119ms/step - loss: 1.5103 - accuracy: 0.3478\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 1.4444 - accuracy: 0.3733\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 1.4170 - accuracy: 0.3910\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.4100 - accuracy: 0.3921\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 119ms/step - loss: 1.3972 - accuracy: 0.3956\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.3896 - accuracy: 0.4077\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.3814 - accuracy: 0.4141\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.3768 - accuracy: 0.4079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 26ms/step\n",
      "[0.4530386740331492, 0.4514601420678769, 0.4483030781373323, 0.44593528018942385, 0.44672454617206, 0.4577742699289661]\n",
      "This is turn:  7\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 18s 115ms/step - loss: 1.7711 - accuracy: 0.2006\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.7554 - accuracy: 0.2033\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 1.7361 - accuracy: 0.2050\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.7225 - accuracy: 0.2250\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.7205 - accuracy: 0.2192\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.6978 - accuracy: 0.2399\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.5885 - accuracy: 0.3027\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.4676 - accuracy: 0.3620\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.4259 - accuracy: 0.3830\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.4087 - accuracy: 0.3920\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.4057 - accuracy: 0.3955\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 119ms/step - loss: 1.3819 - accuracy: 0.4093\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.3828 - accuracy: 0.4009\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.3830 - accuracy: 0.4116\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 1.3870 - accuracy: 0.4073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 26ms/step\n",
      "[0.4530386740331492, 0.4514601420678769, 0.4483030781373323, 0.44593528018942385, 0.44672454617206, 0.4577742699289661, 0.452249408050513]\n",
      "This is turn:  8\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 18s 115ms/step - loss: 1.7698 - accuracy: 0.2011\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.7483 - accuracy: 0.2109\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.7297 - accuracy: 0.2190\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.7223 - accuracy: 0.2318\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.7184 - accuracy: 0.2256\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 1.7131 - accuracy: 0.2423\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 1.6852 - accuracy: 0.2570\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 119ms/step - loss: 1.5855 - accuracy: 0.3189\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.4642 - accuracy: 0.3730\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.4386 - accuracy: 0.3761\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.4123 - accuracy: 0.4033\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.3904 - accuracy: 0.4054\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.3920 - accuracy: 0.4046\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 1.3720 - accuracy: 0.4193\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 1.3670 - accuracy: 0.4143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 25ms/step\n",
      "[0.4530386740331492, 0.4514601420678769, 0.4483030781373323, 0.44593528018942385, 0.44672454617206, 0.4577742699289661, 0.452249408050513, 0.44435674822415155]\n",
      "This is turn:  9\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 113ms/step - loss: 1.7684 - accuracy: 0.1970\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.7544 - accuracy: 0.2161\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.7292 - accuracy: 0.2179\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.7267 - accuracy: 0.2336\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.7161 - accuracy: 0.2385\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.7037 - accuracy: 0.2517\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.6313 - accuracy: 0.2927\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.5440 - accuracy: 0.3297\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.4595 - accuracy: 0.3755\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 1.4214 - accuracy: 0.3907\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 1.4068 - accuracy: 0.3999\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4203 - accuracy: 0.3971\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3991 - accuracy: 0.4094\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3882 - accuracy: 0.4156\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3882 - accuracy: 0.4052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 27ms/step\n",
      "[0.4530386740331492, 0.4514601420678769, 0.4483030781373323, 0.44593528018942385, 0.44672454617206, 0.4577742699289661, 0.452249408050513, 0.44435674822415155, 0.44909234411996846]\n",
      "This is turn:  10\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 107ms/step - loss: 1.7700 - accuracy: 0.1893\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7553 - accuracy: 0.2150\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7394 - accuracy: 0.2095\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7247 - accuracy: 0.2248\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6792 - accuracy: 0.2424\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.5891 - accuracy: 0.3103\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4739 - accuracy: 0.3626\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4341 - accuracy: 0.3752\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3991 - accuracy: 0.3918\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4050 - accuracy: 0.3956\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4081 - accuracy: 0.3887\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3999 - accuracy: 0.3996\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3774 - accuracy: 0.4035\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3820 - accuracy: 0.4037\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3720 - accuracy: 0.4107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 27ms/step\n",
      "[0.4530386740331492, 0.4514601420678769, 0.4483030781373323, 0.44593528018942385, 0.44672454617206, 0.4577742699289661, 0.452249408050513, 0.44435674822415155, 0.44909234411996846, 0.4569850039463299]\n",
      "[0.4530386740331492, 0.4514601420678769, 0.4483030781373323, 0.44593528018942385, 0.44672454617206, 0.4577742699289661, 0.452249408050513, 0.44435674822415155, 0.44909234411996846, 0.4569850039463299]\n",
      "The average for 1,2 is:  0.4505919494869771\n",
      "precision:  [0.45977011 0.4420956  0.4124061  0.41951216 0.62905484 0.57526918] \n",
      " 0.4896846649933811\n",
      "recall:  [0.33962264 0.48192771 0.50301887 0.61120332 0.5576087  0.22596154] \n",
      " 0.4532237956488538\n"
     ]
    }
   ],
   "source": [
    "# Voting Ensemble\n",
    "arr = []\n",
    "pre = []\n",
    "rec = []\n",
    "f1 = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"This is turn: \", i+1)\n",
    "    score, precision, recall = voting_class(1,2)\n",
    "    f = (2*precision*recall)/(precision+recall)\n",
    "    arr.append(score)\n",
    "    pre.append(precision)\n",
    "    rec.append(recall)\n",
    "    f1.append(f)\n",
    "    print(arr)\n",
    "    \n",
    "print(arr)\n",
    "#TAKE FROM ME\n",
    "avg_slight_rf = cal_average(arr)\n",
    "prec_avg = cal_average(pre)\n",
    "rec_avg = cal_average(rec)\n",
    "f1_avg = cal_average(f1)\n",
    "\n",
    "total_prec = cal_average(prec_avg)\n",
    "total_rec = cal_average(rec_avg)\n",
    "total_f1 = cal_average(f1_avg)\n",
    "print(\"The average for 1,2 is: \", avg_slight_rf)\n",
    "print(\"precision: \", prec_avg, '\\n', total_prec)\n",
    "print(\"recall: \", rec_avg, '\\n', total_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration:  0\n",
      "Current array is:  [0.43804262036306235]\n",
      "Current iteration:  1\n",
      "Current array is:  [0.43804262036306235, 0.43804262036306235]\n",
      "Current iteration:  2\n",
      "Current array is:  [0.43804262036306235, 0.43804262036306235, 0.43804262036306235]\n",
      "Current iteration:  3\n",
      "Current array is:  [0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235]\n",
      "Current iteration:  4\n",
      "Current array is:  [0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235]\n",
      "Current iteration:  5\n",
      "Current array is:  [0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235]\n",
      "Current iteration:  6\n",
      "Current array is:  [0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235]\n",
      "Current iteration:  7\n",
      "Current array is:  [0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235]\n",
      "Current iteration:  8\n",
      "Current array is:  [0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235]\n",
      "Current iteration:  9\n",
      "Current array is:  [0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235]\n",
      "Current iteration:  0\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 108ms/step - loss: 1.7695 - accuracy: 0.1963\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7534 - accuracy: 0.2001\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7254 - accuracy: 0.2207\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7205 - accuracy: 0.2164\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7131 - accuracy: 0.2347\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7012 - accuracy: 0.2404\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.6716 - accuracy: 0.2660\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.5449 - accuracy: 0.3414\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4743 - accuracy: 0.3599\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4310 - accuracy: 0.3793\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4187 - accuracy: 0.3942\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3788 - accuracy: 0.4150\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3619 - accuracy: 0.4234\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3777 - accuracy: 0.4235\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3696 - accuracy: 0.4154\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 107ms/step - loss: 1.7682 - accuracy: 0.1919\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7549 - accuracy: 0.2030\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7251 - accuracy: 0.2137\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7181 - accuracy: 0.2247\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7136 - accuracy: 0.2204\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6948 - accuracy: 0.2465\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.6117 - accuracy: 0.3017\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4770 - accuracy: 0.3650\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4370 - accuracy: 0.3901\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4134 - accuracy: 0.3985\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3927 - accuracy: 0.4161\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3867 - accuracy: 0.4195\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3647 - accuracy: 0.4237\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3602 - accuracy: 0.4338\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3552 - accuracy: 0.4254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 27ms/step\n",
      "10/10 [==============================] - 1s 28ms/step\n",
      "Current array is:  [0.3914759273875296]\n",
      "Current iteration:  1\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 103ms/step - loss: 1.7700 - accuracy: 0.1985\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 1.7504 - accuracy: 0.2034\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 1.7316 - accuracy: 0.2030\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.7198 - accuracy: 0.2216\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.7133 - accuracy: 0.2187\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 1.6831 - accuracy: 0.2512\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.5811 - accuracy: 0.3110\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.4956 - accuracy: 0.3626\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 1.4102 - accuracy: 0.3949\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4199 - accuracy: 0.3956\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3788 - accuracy: 0.4140\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3673 - accuracy: 0.4214\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3676 - accuracy: 0.4205\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3614 - accuracy: 0.4241\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3437 - accuracy: 0.4332\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 19s 111ms/step - loss: 1.7692 - accuracy: 0.1958\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7516 - accuracy: 0.2124\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.7339 - accuracy: 0.2142\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7167 - accuracy: 0.2292\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7172 - accuracy: 0.2330\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.6967 - accuracy: 0.2477\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.6939 - accuracy: 0.2555\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.6822 - accuracy: 0.2668\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.6128 - accuracy: 0.3079\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.5064 - accuracy: 0.3427\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.4459 - accuracy: 0.3865\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4182 - accuracy: 0.3991\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3991 - accuracy: 0.4121\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3750 - accuracy: 0.4176\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3536 - accuracy: 0.4290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 25ms/step\n",
      "10/10 [==============================] - 2s 26ms/step\n",
      "Current array is:  [0.3914759273875296, 0.39463299131807417]\n",
      "Current iteration:  2\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 113ms/step - loss: 1.7729 - accuracy: 0.1856\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.7452 - accuracy: 0.2067\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.7267 - accuracy: 0.2125\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.7262 - accuracy: 0.2086\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.7126 - accuracy: 0.2272\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.7002 - accuracy: 0.2330\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.6874 - accuracy: 0.2499\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.6731 - accuracy: 0.2642\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.5904 - accuracy: 0.3194\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.4830 - accuracy: 0.3637\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.4182 - accuracy: 0.3960\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3914 - accuracy: 0.4133\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 10s 122ms/step - loss: 1.3711 - accuracy: 0.4199\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3724 - accuracy: 0.4287\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 119ms/step - loss: 1.3682 - accuracy: 0.4327\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 105ms/step - loss: 1.7674 - accuracy: 0.1967\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.7537 - accuracy: 0.2001\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.7269 - accuracy: 0.2246\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 1.7167 - accuracy: 0.2324\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.7095 - accuracy: 0.2288\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.6944 - accuracy: 0.2569\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.6561 - accuracy: 0.2832\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.5520 - accuracy: 0.3410\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.4449 - accuracy: 0.3834\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 1.4212 - accuracy: 0.4067\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 1.4033 - accuracy: 0.4076\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.4073 - accuracy: 0.4092\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 1.3650 - accuracy: 0.4341\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.3657 - accuracy: 0.4307\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.3560 - accuracy: 0.4302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 27ms/step\n",
      "10/10 [==============================] - 1s 28ms/step\n",
      "Current array is:  [0.3914759273875296, 0.39463299131807417, 0.39542225730071034]\n",
      "Current iteration:  3\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 105ms/step - loss: 1.7706 - accuracy: 0.1977\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7552 - accuracy: 0.2029\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 1.7214 - accuracy: 0.2201\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.7169 - accuracy: 0.2175\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.7037 - accuracy: 0.2202\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.6758 - accuracy: 0.2637\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.6000 - accuracy: 0.2996\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.4929 - accuracy: 0.3601\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.4338 - accuracy: 0.3877\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.4097 - accuracy: 0.3929\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3889 - accuracy: 0.4055\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3888 - accuracy: 0.4082\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.3824 - accuracy: 0.4103\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3645 - accuracy: 0.4181\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3631 - accuracy: 0.4237\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 106ms/step - loss: 1.7714 - accuracy: 0.2095\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7561 - accuracy: 0.2099\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7307 - accuracy: 0.2080\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7174 - accuracy: 0.2201\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7091 - accuracy: 0.2290\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6939 - accuracy: 0.2463\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6731 - accuracy: 0.2661\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.5663 - accuracy: 0.3287\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4569 - accuracy: 0.3794\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.4205 - accuracy: 0.3939\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4145 - accuracy: 0.3880\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3940 - accuracy: 0.4111\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3876 - accuracy: 0.4174\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3743 - accuracy: 0.4189\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3685 - accuracy: 0.4268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 27ms/step\n",
      "10/10 [==============================] - 1s 27ms/step\n",
      "Current array is:  [0.3914759273875296, 0.39463299131807417, 0.39542225730071034, 0.39542225730071034]\n",
      "Current iteration:  4\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 104ms/step - loss: 1.7736 - accuracy: 0.1862\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7408 - accuracy: 0.2109\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7251 - accuracy: 0.2132\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7218 - accuracy: 0.2255\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7109 - accuracy: 0.2445\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.7034 - accuracy: 0.2491\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.6867 - accuracy: 0.2638\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6602 - accuracy: 0.2812\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.5866 - accuracy: 0.3232\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.4558 - accuracy: 0.3797\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.4017 - accuracy: 0.4111\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3875 - accuracy: 0.4258\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3845 - accuracy: 0.4212\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3645 - accuracy: 0.4319\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3638 - accuracy: 0.4298\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 104ms/step - loss: 1.7707 - accuracy: 0.1972\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.7554 - accuracy: 0.2073\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 1.7256 - accuracy: 0.2146\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 1.7214 - accuracy: 0.2169\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7171 - accuracy: 0.2247\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7028 - accuracy: 0.2462\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.6925 - accuracy: 0.2528\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.6650 - accuracy: 0.2718\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.5251 - accuracy: 0.3365\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.4537 - accuracy: 0.3787\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4074 - accuracy: 0.3925\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3962 - accuracy: 0.4128\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3991 - accuracy: 0.4143\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3870 - accuracy: 0.4053\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3686 - accuracy: 0.4265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 26ms/step\n",
      "10/10 [==============================] - 2s 26ms/step\n",
      "Current array is:  [0.3914759273875296, 0.39463299131807417, 0.39542225730071034, 0.39542225730071034, 0.3812154696132597]\n",
      "Current iteration:  5\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 19s 112ms/step - loss: 1.7717 - accuracy: 0.1859\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.7544 - accuracy: 0.2094\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.7275 - accuracy: 0.2185\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.7225 - accuracy: 0.2245\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.7069 - accuracy: 0.2462\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.6977 - accuracy: 0.2598\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.6851 - accuracy: 0.2542\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.6395 - accuracy: 0.2941\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.5354 - accuracy: 0.3478\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.4397 - accuracy: 0.3954\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.3962 - accuracy: 0.4207\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3717 - accuracy: 0.4292\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.3639 - accuracy: 0.4285\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3646 - accuracy: 0.4262\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3516 - accuracy: 0.4396\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 111ms/step - loss: 1.7702 - accuracy: 0.1977\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7610 - accuracy: 0.2068\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7304 - accuracy: 0.2198\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7214 - accuracy: 0.2265\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.7079 - accuracy: 0.2424\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.6679 - accuracy: 0.2674\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.5928 - accuracy: 0.3131\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.4739 - accuracy: 0.3654\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.4305 - accuracy: 0.3846\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3983 - accuracy: 0.4101\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3907 - accuracy: 0.4168\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3798 - accuracy: 0.4242\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3643 - accuracy: 0.4269\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3768 - accuracy: 0.4203\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3584 - accuracy: 0.4313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 26ms/step\n",
      "10/10 [==============================] - 2s 26ms/step\n",
      "Current array is:  [0.3914759273875296, 0.39463299131807417, 0.39542225730071034, 0.39542225730071034, 0.3812154696132597, 0.38910812943962114]\n",
      "Current iteration:  6\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 113ms/step - loss: 1.7699 - accuracy: 0.1891\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.7428 - accuracy: 0.2072\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.7306 - accuracy: 0.2108\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7197 - accuracy: 0.2189\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.7096 - accuracy: 0.2291\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.7032 - accuracy: 0.2424\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.6868 - accuracy: 0.2476\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.6294 - accuracy: 0.2950\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.4972 - accuracy: 0.3638\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.4145 - accuracy: 0.3999\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.3920 - accuracy: 0.4013\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3849 - accuracy: 0.4146\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3706 - accuracy: 0.4146\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.3542 - accuracy: 0.4298\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3663 - accuracy: 0.4281\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 19s 110ms/step - loss: 1.7696 - accuracy: 0.1980\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7574 - accuracy: 0.2002\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7389 - accuracy: 0.2085\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7216 - accuracy: 0.2212\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7187 - accuracy: 0.2384\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.6987 - accuracy: 0.2480\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.6645 - accuracy: 0.2781\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.5602 - accuracy: 0.3281\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.4642 - accuracy: 0.3776\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4188 - accuracy: 0.3968\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4065 - accuracy: 0.4039\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3777 - accuracy: 0.4092\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3752 - accuracy: 0.4155\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3776 - accuracy: 0.4181\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3808 - accuracy: 0.4169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 26ms/step\n",
      "10/10 [==============================] - 2s 25ms/step\n",
      "Current array is:  [0.3914759273875296, 0.39463299131807417, 0.39542225730071034, 0.39542225730071034, 0.3812154696132597, 0.38910812943962114, 0.3804262036306235]\n",
      "Current iteration:  7\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 110ms/step - loss: 1.7721 - accuracy: 0.1931\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7558 - accuracy: 0.2012\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7238 - accuracy: 0.2192\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7145 - accuracy: 0.2311\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.6914 - accuracy: 0.2493\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.6427 - accuracy: 0.2744\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.5583 - accuracy: 0.3295\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4667 - accuracy: 0.3742\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4065 - accuracy: 0.3984\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4092 - accuracy: 0.4043\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3852 - accuracy: 0.4057\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3803 - accuracy: 0.4133\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 119ms/step - loss: 1.3634 - accuracy: 0.4210\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3634 - accuracy: 0.4266\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3531 - accuracy: 0.4295\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 18s 110ms/step - loss: 1.7713 - accuracy: 0.1917\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7523 - accuracy: 0.2010\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7238 - accuracy: 0.2157\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7227 - accuracy: 0.2302\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7156 - accuracy: 0.2369\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7050 - accuracy: 0.2469\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.6856 - accuracy: 0.2589\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.6532 - accuracy: 0.2873\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.5495 - accuracy: 0.3448\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.4634 - accuracy: 0.3791\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.4174 - accuracy: 0.3986\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.4131 - accuracy: 0.4047\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3752 - accuracy: 0.4113\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3727 - accuracy: 0.4297\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3583 - accuracy: 0.4325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 25ms/step\n",
      "10/10 [==============================] - 2s 26ms/step\n",
      "Current array is:  [0.3914759273875296, 0.39463299131807417, 0.39542225730071034, 0.39542225730071034, 0.3812154696132597, 0.38910812943962114, 0.3804262036306235, 0.40094711917916337]\n",
      "Current iteration:  8\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 19s 111ms/step - loss: 1.7733 - accuracy: 0.1883\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7474 - accuracy: 0.2013\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.7306 - accuracy: 0.2159\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7219 - accuracy: 0.2346\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.7062 - accuracy: 0.2288\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.6937 - accuracy: 0.2481\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.6684 - accuracy: 0.2726\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.5679 - accuracy: 0.3240\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.4458 - accuracy: 0.3779\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.4180 - accuracy: 0.3930\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.4021 - accuracy: 0.4100\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3830 - accuracy: 0.4149\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 1.3654 - accuracy: 0.4206\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3530 - accuracy: 0.4348\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3594 - accuracy: 0.4310\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 18s 113ms/step - loss: 1.7717 - accuracy: 0.1982\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7574 - accuracy: 0.1978\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.7360 - accuracy: 0.2129\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.7192 - accuracy: 0.2178\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7121 - accuracy: 0.2316\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.6963 - accuracy: 0.2527\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.6752 - accuracy: 0.2775\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.5946 - accuracy: 0.3175\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4812 - accuracy: 0.3610\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.4277 - accuracy: 0.4002\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.3953 - accuracy: 0.4065\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3988 - accuracy: 0.4032\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3845 - accuracy: 0.4184\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3716 - accuracy: 0.4238\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3731 - accuracy: 0.4247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 26ms/step\n",
      "10/10 [==============================] - 2s 26ms/step\n",
      "Current array is:  [0.3914759273875296, 0.39463299131807417, 0.39542225730071034, 0.39542225730071034, 0.3812154696132597, 0.38910812943962114, 0.3804262036306235, 0.40094711917916337, 0.3796369376479874]\n",
      "Current iteration:  9\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 114ms/step - loss: 1.7711 - accuracy: 0.1937\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.7538 - accuracy: 0.2077\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7336 - accuracy: 0.2099\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7259 - accuracy: 0.2134\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.7081 - accuracy: 0.2346\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7015 - accuracy: 0.2341\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.6818 - accuracy: 0.2535\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.6375 - accuracy: 0.2745\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.5098 - accuracy: 0.3572\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.4385 - accuracy: 0.3824\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 1.4049 - accuracy: 0.4028\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3866 - accuracy: 0.4135\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3611 - accuracy: 0.4267\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3680 - accuracy: 0.4276\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3671 - accuracy: 0.4317\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 18s 110ms/step - loss: 1.7708 - accuracy: 0.1947\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.7552 - accuracy: 0.1925\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7388 - accuracy: 0.2109\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7178 - accuracy: 0.2220\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7183 - accuracy: 0.2270\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7048 - accuracy: 0.2456\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.6856 - accuracy: 0.2662\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.6526 - accuracy: 0.2863\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.5295 - accuracy: 0.3464\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.4352 - accuracy: 0.3842\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4180 - accuracy: 0.3964\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.4061 - accuracy: 0.4067\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3790 - accuracy: 0.4218\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3743 - accuracy: 0.4238\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3725 - accuracy: 0.4224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 26ms/step\n",
      "10/10 [==============================] - 2s 25ms/step\n",
      "Current array is:  [0.3914759273875296, 0.39463299131807417, 0.39542225730071034, 0.39542225730071034, 0.3812154696132597, 0.38910812943962114, 0.3804262036306235, 0.40094711917916337, 0.3796369376479874, 0.3741120757695343]\n",
      "The average for the BI-LSTM:  0.3882399368587214\n",
      "The average for the Random Forest:  0.3882399368587214\n"
     ]
    }
   ],
   "source": [
    "# Bagging Ensemble\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "arr_bag_rf = []\n",
    "arr_bag_nn = []\n",
    "\n",
    "def test_bagging_rf():\n",
    "    mod = BaggingClassifier(base_estimator=RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1),\n",
    "                         n_estimators=10, random_state=0)\n",
    "    \n",
    "    mod = mod.fit(rf_2_train, train[\"Label\"])\n",
    "    \n",
    "    t = test['Label']\n",
    "    v = valid['Label']\n",
    "    \n",
    "    mod_test = mod.predict(rf_2_test)\n",
    "    mod_score = accuracy_score(t, mod_test)\n",
    "    \n",
    "    return mod_score\n",
    "\n",
    "def test_bagging_nn():\n",
    "    mod = BaggingClassifier(base_estimator=kModel,\n",
    "                         n_estimators=2, random_state=0)\n",
    "    mod = mod.fit(rf_2_train, train[\"Label\"])\n",
    "    \n",
    "    t = test['Label']\n",
    "    v = valid['Label']\n",
    "    \n",
    "    mod_test = mod.predict(rf_2_test)\n",
    "    mod_score = accuracy_score(t, mod_test)\n",
    "    \n",
    "    return mod_score\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Current iteration: \", i)\n",
    "    \n",
    "    score = test_bagging_rf()\n",
    "    arr_bag_rf.append(score)\n",
    "    print(\"Current array is: \", arr_bag_rf)\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Current iteration: \", i)\n",
    "    \n",
    "    score = test_bagging_nn()\n",
    "    arr_bag_nn.append(score)\n",
    "    print(\"Current array is: \", arr_bag_nn)\n",
    "\n",
    "avg_bag_nn = cal_average(arr_bag_nn)\n",
    "avg_bag_rf = cal_average(arr_bag_nn)\n",
    "\n",
    "print(\"The average for the BI-LSTM: \", avg_bag_nn)\n",
    "print(\"The average for the Random Forest: \", avg_bag_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration:  0\n",
      "Current iteration:  1\n",
      "Current iteration:  2\n",
      "Current iteration:  3\n",
      "Current iteration:  4\n",
      "Current iteration:  5\n",
      "Current iteration:  6\n",
      "Current iteration:  7\n",
      "Current iteration:  8\n",
      "Current iteration:  9\n",
      "The average for boosting is:  0.4317284925019732\n"
     ]
    }
   ],
   "source": [
    "# Boosting ensemble\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "arr_boost = []\n",
    "\n",
    "def test_boosting():\n",
    "    boost_test = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "     max_depth=1, random_state=0)\n",
    "    \n",
    "    boost_test = boost_test.fit(rf_2_train, train[\"Label\"])\n",
    "    \n",
    "    t = test['Label']\n",
    "    v = valid['Label']\n",
    "\n",
    "    return boost_test.score(rf_2_test,t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Current iteration: \", i)\n",
    "    score = test_boosting()\n",
    "    arr_boost.append(score)\n",
    "\n",
    "avg_boost = cal_average(arr_boost)\n",
    "\n",
    "print(\"The average for boosting is: \", avg_boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model's Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,2,1])\n",
    "\n",
    "langs = [ 'Random Forest', 'Ensemble', 'Bi-LSTM', 'Bagging Random Forest', 'Bagging Bi-LSTM', 'Boosting']\n",
    "scores = [ normal_t-0.35, avg_slight_rf-0.35, accr[1]-0.35, avg_bag_rf-0.35, avg_bag_nn-0.35, avg_boost-0.35 ]\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Testing set')\n",
    "\n",
    "ax.bar(langs,scores, bottom=0.35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision of the model:  0.4896846649933811\n"
     ]
    }
   ],
   "source": [
    "# Print out the precision score of the best ensemble method\n",
    "print(\"The precision of the model: \" ,total_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recall of the model:  0.4532237956488538\n"
     ]
    }
   ],
   "source": [
    "# Print out the recall score of the best ensemble method\n",
    "print(\"The recall of the model: \", total_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1-score of the model:  0.4527000642459221\n"
     ]
    }
   ],
   "source": [
    "# Print out the f-1 score of the best ensemble method\n",
    "print(\"The f1-score of the model: \", total_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final accuracy of the ensemble model:  0.4505919494869771\n"
     ]
    }
   ],
   "source": [
    "# Print out the accuracy score of the best ensemble method\n",
    "print(\"The final accuracy of the ensemble model: \", avg_slight_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is:  0.44672454617206003\n",
      "Valid score is:  0.4369158878504673\n",
      "The non selected score is:  0.4230465666929755\n"
     ]
    }
   ],
   "source": [
    "# Display the difference that the feature selection process makes, as shown\n",
    "# through the use of the random forest classifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,2,1])\n",
    "\n",
    "langs = [ 'Random Forest', 'Random Forest Without Feature Selection']\n",
    "scores = [ normal_t-0.4, rf_test_sc-0.4 ]\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Testing set')\n",
    "\n",
    "ax.bar(langs,scores, bottom=0.4)\n",
    "plt.show()\n",
    "\n",
    "print(\"Test score is: \", normal_t)\n",
    "print(\"Valid score is: \", normal_v)\n",
    "print(\"The non selected score is: \", rf_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
