{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('liar_dataset/test.tsv', sep='\\t', header=None) \n",
    "valid = pd.read_csv('liar_dataset/valid.tsv', sep='\\t', header=None)\n",
    "\n",
    "#Adding Columns - test\n",
    "test.columns=[\"Statement_ID\",\"Label\", \"Statement\", \"Subject(s)\", \"Speaker\", \"Speaker_Job\", \"State\", \"Party\", \"Barely_True_History\", \n",
    "             \"False_History\", \"Half_True_History\", \"Mostly_True_History\", \"Pants_On_Fire_History\",\"Context\"]\n",
    "\n",
    "#Adding Columns - valid\n",
    "valid.columns=[\"Statement_ID\",\"Label\", \"Statement\", \"Subject(s)\", \"Speaker\", \"Speaker_Job\", \"State\", \"Party\", \"Barely_True_History\", \n",
    "             \"False_History\", \"Half_True_History\", \"Mostly_True_History\", \"Pants_On_Fire_History\",\"Context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correctly loads the dataset with no wrong columns\n",
    "train = pd.read_csv('liar_dataset/train.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statement_ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Subject(s)</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Speaker_Job</th>\n",
       "      <th>State</th>\n",
       "      <th>Party</th>\n",
       "      <th>Barely_True_History</th>\n",
       "      <th>False_History</th>\n",
       "      <th>Half_True_History</th>\n",
       "      <th>Mostly_True_History</th>\n",
       "      <th>Pants_On_Fire_History</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Statement_ID        Label  \\\n",
       "0    2635.json        false   \n",
       "1   10540.json    half-true   \n",
       "2     324.json  mostly-true   \n",
       "3    1123.json        false   \n",
       "4    9028.json    half-true   \n",
       "\n",
       "                                           Statement  \\\n",
       "0  Says the Annies List political group supports ...   \n",
       "1  When did the decline of coal start? It started...   \n",
       "2  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3  Health care reform legislation is likely to ma...   \n",
       "4  The economic turnaround started at the end of ...   \n",
       "\n",
       "                           Subject(s)         Speaker           Speaker_Job  \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "3                         health-care    blog-posting                   NaN   \n",
       "4                        economy,jobs   charlie-crist                   NaN   \n",
       "\n",
       "      State       Party  Barely_True_History  False_History  \\\n",
       "0     Texas  republican                  0.0            1.0   \n",
       "1  Virginia    democrat                  0.0            0.0   \n",
       "2  Illinois    democrat                 70.0           71.0   \n",
       "3       NaN        none                  7.0           19.0   \n",
       "4   Florida    democrat                 15.0            9.0   \n",
       "\n",
       "   Half_True_History  Mostly_True_History  Pants_On_Fire_History  \\\n",
       "0                0.0                  0.0                    0.0   \n",
       "1                1.0                  1.0                    0.0   \n",
       "2              160.0                163.0                    9.0   \n",
       "3                3.0                  5.0                   44.0   \n",
       "4               20.0                 19.0                    2.0   \n",
       "\n",
       "               Context  \n",
       "0             a mailer  \n",
       "1      a floor speech.  \n",
       "2               Denver  \n",
       "3       a news release  \n",
       "4  an interview on CNN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding Columns\n",
    "train.columns=[\"Statement_ID\",\"Label\", \"Statement\", \"Subject(s)\", \"Speaker\", \"Speaker_Job\", \"State\", \"Party\", \"Barely_True_History\", \n",
    "             \"False_History\", \"Half_True_History\", \"Mostly_True_History\", \"Pants_On_Fire_History\",\"Context\"]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine sets to have same number of features towards the end\n",
    "df = pd.concat([train, test, valid], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan in each columns:\n",
      "Statement_ID                0\n",
      "Label                       0\n",
      "Statement                   0\n",
      "Subject(s)                  2\n",
      "Speaker                     2\n",
      "Speaker_Job              3567\n",
      "State                    2749\n",
      "Party                       2\n",
      "Barely_True_History         2\n",
      "False_History               2\n",
      "Half_True_History           2\n",
      "Mostly_True_History         2\n",
      "Pants_On_Fire_History       2\n",
      "Context                   131\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Nan in each columns:\" , df.isna().sum(), sep='\\n')#print out the number of NaN entries in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing NaN\n",
    "df['Barely_True_History'] = df['Barely_True_History'].fillna(0.0) # Fill NaN with 0.0\n",
    "df['False_History'] = df['False_History'].fillna(0.0) # Fill NaN with 0.0\n",
    "df['Half_True_History'] = df['Half_True_History'].fillna(0.0) # Fill NaN with 0.0\n",
    "df['Mostly_True_History'] = df['Mostly_True_History'].fillna(0.0) # Fill NaN with 0.0\n",
    "df['Pants_On_Fire_History'] = df['Pants_On_Fire_History'].fillna(0.0) # Fill NaN with 0.0\n",
    "\n",
    "df = df.fillna(0.0) # fill all NaN with 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan in each columns:\n",
      "Statement_ID             0\n",
      "Label                    0\n",
      "Statement                0\n",
      "Subject(s)               0\n",
      "Speaker                  0\n",
      "Speaker_Job              0\n",
      "State                    0\n",
      "Party                    0\n",
      "Barely_True_History      0\n",
      "False_History            0\n",
      "Half_True_History        0\n",
      "Mostly_True_History      0\n",
      "Pants_On_Fire_History    0\n",
      "Context                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Nan in each columns:\" , df.isna().sum(), sep='\\n')#print out the number of NaN entries in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label                                          Statement\n",
       "0        false  Says the Annies List political group supports ...\n",
       "1    half-true  When did the decline of coal start? It started...\n",
       "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...\n",
       "3        false  Health care reform legislation is likely to ma...\n",
       "4    half-true  The economic turnaround started at the end of ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df[['Label', 'Statement']].copy() # Make copy dataset to work off of.\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>body_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>When did the decline of coal start It started ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>Hillary Clinton agrees with John McCain by vot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label                                          Statement  \\\n",
       "0        false  Says the Annies List political group supports ...   \n",
       "1    half-true  When did the decline of coal start? It started...   \n",
       "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3        false  Health care reform legislation is likely to ma...   \n",
       "4    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                     body_text_clean  \n",
       "0  Says the Annies List political group supports ...  \n",
       "1  When did the decline of coal start It started ...  \n",
       "2  Hillary Clinton agrees with John McCain by vot...  \n",
       "3  Health care reform legislation is likely to ma...  \n",
       "4  The economic turnaround started at the end of ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct\n",
    "\n",
    "df_clean['body_text_clean'] = df_clean['Statement'].apply(lambda x: remove_punct(x))\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>[says, the, annies, list, political, group, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>When did the decline of coal start It started ...</td>\n",
       "      <td>[when, did, the, decline, of, coal, start, it,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>Hillary Clinton agrees with John McCain by vot...</td>\n",
       "      <td>[hillary, clinton, agrees, with, john, mccain,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>[health, care, reform, legislation, is, likely...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>[the, economic, turnaround, started, at, the, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label                                          Statement  \\\n",
       "0        false  Says the Annies List political group supports ...   \n",
       "1    half-true  When did the decline of coal start? It started...   \n",
       "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3        false  Health care reform legislation is likely to ma...   \n",
       "4    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Says the Annies List political group supports ...   \n",
       "1  When did the decline of coal start It started ...   \n",
       "2  Hillary Clinton agrees with John McCain by vot...   \n",
       "3  Health care reform legislation is likely to ma...   \n",
       "4  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                 body_text_tokenized  \n",
       "0  [says, the, annies, list, political, group, su...  \n",
       "1  [when, did, the, decline, of, coal, start, it,...  \n",
       "2  [hillary, clinton, agrees, with, john, mccain,...  \n",
       "3  [health, care, reform, legislation, is, likely...  \n",
       "4  [the, economic, turnaround, started, at, the, ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    #tokens = \" \".join(word for word in tokens)\n",
    "    return tokens\n",
    "\n",
    "df_clean['body_text_tokenized'] = df_clean['body_text_clean'].apply(lambda x: tokenize(x.lower()))\n",
    "\n",
    "\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>[says, the, annies, list, political, group, su...</td>\n",
       "      <td>[says, annies, list, political, group, support...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>When did the decline of coal start It started ...</td>\n",
       "      <td>[when, did, the, decline, of, coal, start, it,...</td>\n",
       "      <td>[decline, coal, start, started, natural, gas, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>Hillary Clinton agrees with John McCain by vot...</td>\n",
       "      <td>[hillary, clinton, agrees, with, john, mccain,...</td>\n",
       "      <td>[hillary, clinton, agrees, john, mccain, votin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>[health, care, reform, legislation, is, likely...</td>\n",
       "      <td>[health, care, reform, legislation, likely, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>[the, economic, turnaround, started, at, the, ...</td>\n",
       "      <td>[economic, turnaround, started, end, term]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label                                          Statement  \\\n",
       "0        false  Says the Annies List political group supports ...   \n",
       "1    half-true  When did the decline of coal start? It started...   \n",
       "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3        false  Health care reform legislation is likely to ma...   \n",
       "4    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Says the Annies List political group supports ...   \n",
       "1  When did the decline of coal start It started ...   \n",
       "2  Hillary Clinton agrees with John McCain by vot...   \n",
       "3  Health care reform legislation is likely to ma...   \n",
       "4  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [says, the, annies, list, political, group, su...   \n",
       "1  [when, did, the, decline, of, coal, start, it,...   \n",
       "2  [hillary, clinton, agrees, with, john, mccain,...   \n",
       "3  [health, care, reform, legislation, is, likely...   \n",
       "4  [the, economic, turnaround, started, at, the, ...   \n",
       "\n",
       "                                    body_text_nostop  \n",
       "0  [says, annies, list, political, group, support...  \n",
       "1  [decline, coal, start, started, natural, gas, ...  \n",
       "2  [hillary, clinton, agrees, john, mccain, votin...  \n",
       "3  [health, care, reform, legislation, likely, ma...  \n",
       "4         [economic, turnaround, started, end, term]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(tokenized_list):\n",
    "    text = [word for word in tokenized_list if word not in stopword]\n",
    "    return text\n",
    "\n",
    "df_clean['body_text_nostop'] = df_clean['body_text_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing/Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "      <th>body_text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>[says, the, annies, list, political, group, su...</td>\n",
       "      <td>[says, annies, list, political, group, support...</td>\n",
       "      <td>[say, annies, list, political, group, support,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>When did the decline of coal start It started ...</td>\n",
       "      <td>[when, did, the, decline, of, coal, start, it,...</td>\n",
       "      <td>[decline, coal, start, started, natural, gas, ...</td>\n",
       "      <td>[decline, coal, start, started, natural, gas, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>Hillary Clinton agrees with John McCain by vot...</td>\n",
       "      <td>[hillary, clinton, agrees, with, john, mccain,...</td>\n",
       "      <td>[hillary, clinton, agrees, john, mccain, votin...</td>\n",
       "      <td>[hillary, clinton, agrees, john, mccain, votin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>[health, care, reform, legislation, is, likely...</td>\n",
       "      <td>[health, care, reform, legislation, likely, ma...</td>\n",
       "      <td>[health, care, reform, legislation, likely, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>[the, economic, turnaround, started, at, the, ...</td>\n",
       "      <td>[economic, turnaround, started, end, term]</td>\n",
       "      <td>[economic, turnaround, started, end, term]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label                                          Statement  \\\n",
       "0        false  Says the Annies List political group supports ...   \n",
       "1    half-true  When did the decline of coal start? It started...   \n",
       "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3        false  Health care reform legislation is likely to ma...   \n",
       "4    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Says the Annies List political group supports ...   \n",
       "1  When did the decline of coal start It started ...   \n",
       "2  Hillary Clinton agrees with John McCain by vot...   \n",
       "3  Health care reform legislation is likely to ma...   \n",
       "4  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [says, the, annies, list, political, group, su...   \n",
       "1  [when, did, the, decline, of, coal, start, it,...   \n",
       "2  [hillary, clinton, agrees, with, john, mccain,...   \n",
       "3  [health, care, reform, legislation, is, likely...   \n",
       "4  [the, economic, turnaround, started, at, the, ...   \n",
       "\n",
       "                                    body_text_nostop  \\\n",
       "0  [says, annies, list, political, group, support...   \n",
       "1  [decline, coal, start, started, natural, gas, ...   \n",
       "2  [hillary, clinton, agrees, john, mccain, votin...   \n",
       "3  [health, care, reform, legislation, likely, ma...   \n",
       "4         [economic, turnaround, started, end, term]   \n",
       "\n",
       "                                body_text_lemmatized  \n",
       "0  [say, annies, list, political, group, support,...  \n",
       "1  [decline, coal, start, started, natural, gas, ...  \n",
       "2  [hillary, clinton, agrees, john, mccain, votin...  \n",
       "3  [health, care, reform, legislation, likely, ma...  \n",
       "4         [economic, turnaround, started, end, term]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatizing is more accurate but slower\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizing(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text\n",
    "\n",
    "df_clean['body_text_lemmatized'] = df_clean['body_text_nostop'].apply(lambda x: lemmatizing(x))\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "      <th>body_text_lemmatized</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>[says, the, annies, list, political, group, su...</td>\n",
       "      <td>[says, annies, list, political, group, support...</td>\n",
       "      <td>[say, annies, list, political, group, support,...</td>\n",
       "      <td>say annies list political group support thirdt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>When did the decline of coal start It started ...</td>\n",
       "      <td>[when, did, the, decline, of, coal, start, it,...</td>\n",
       "      <td>[decline, coal, start, started, natural, gas, ...</td>\n",
       "      <td>[decline, coal, start, started, natural, gas, ...</td>\n",
       "      <td>decline coal start started natural gas took st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>Hillary Clinton agrees with John McCain by vot...</td>\n",
       "      <td>[hillary, clinton, agrees, with, john, mccain,...</td>\n",
       "      <td>[hillary, clinton, agrees, john, mccain, votin...</td>\n",
       "      <td>[hillary, clinton, agrees, john, mccain, votin...</td>\n",
       "      <td>hillary clinton agrees john mccain voting give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>[health, care, reform, legislation, is, likely...</td>\n",
       "      <td>[health, care, reform, legislation, likely, ma...</td>\n",
       "      <td>[health, care, reform, legislation, likely, ma...</td>\n",
       "      <td>health care reform legislation likely mandate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>[the, economic, turnaround, started, at, the, ...</td>\n",
       "      <td>[economic, turnaround, started, end, term]</td>\n",
       "      <td>[economic, turnaround, started, end, term]</td>\n",
       "      <td>economic turnaround started end term</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label                                          Statement  \\\n",
       "0        false  Says the Annies List political group supports ...   \n",
       "1    half-true  When did the decline of coal start? It started...   \n",
       "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3        false  Health care reform legislation is likely to ma...   \n",
       "4    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Says the Annies List political group supports ...   \n",
       "1  When did the decline of coal start It started ...   \n",
       "2  Hillary Clinton agrees with John McCain by vot...   \n",
       "3  Health care reform legislation is likely to ma...   \n",
       "4  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [says, the, annies, list, political, group, su...   \n",
       "1  [when, did, the, decline, of, coal, start, it,...   \n",
       "2  [hillary, clinton, agrees, with, john, mccain,...   \n",
       "3  [health, care, reform, legislation, is, likely...   \n",
       "4  [the, economic, turnaround, started, at, the, ...   \n",
       "\n",
       "                                    body_text_nostop  \\\n",
       "0  [says, annies, list, political, group, support...   \n",
       "1  [decline, coal, start, started, natural, gas, ...   \n",
       "2  [hillary, clinton, agrees, john, mccain, votin...   \n",
       "3  [health, care, reform, legislation, likely, ma...   \n",
       "4         [economic, turnaround, started, end, term]   \n",
       "\n",
       "                                body_text_lemmatized  \\\n",
       "0  [say, annies, list, political, group, support,...   \n",
       "1  [decline, coal, start, started, natural, gas, ...   \n",
       "2  [hillary, clinton, agrees, john, mccain, votin...   \n",
       "3  [health, care, reform, legislation, likely, ma...   \n",
       "4         [economic, turnaround, started, end, term]   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  say annies list political group support thirdt...  \n",
       "1  decline coal start started natural gas took st...  \n",
       "2  hillary clinton agrees john mccain voting give...  \n",
       "3  health care reform legislation likely mandate ...  \n",
       "4               economic turnaround started end term  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are a few different types of vectorization:\n",
    "# 1. Count Vectorization: Takes single words\n",
    "# 2. N-grams: Takes groups of words (i.e. strings)\n",
    "# 3. Term frequency - inverse document frequency (TF-IDF): Back to single words\n",
    "# For the testing purposes of this Thesis, we can just start by using TF-IDF (N-grams too long, CV not too bad)\n",
    "\n",
    "# Make list into single string\n",
    "def toll(text):\n",
    "    text = \" \".join(word for word in text)\n",
    "    return text\n",
    "\n",
    "df_clean['cleaned_text'] = df_clean['body_text_lemmatized'].apply(lambda x: toll(x))\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12791, 13141)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vect.fit_transform(df_clean['cleaned_text']) # Read in the pre-processed data\n",
    "\n",
    "print(X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>004</th>\n",
       "      <th>005</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>025</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>047</th>\n",
       "      <th>05</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>zippo</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zuckerbergs</th>\n",
       "      <th>zvisa</th>\n",
       "      <th>ʺmore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12786</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12789</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12790</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12791 rows × 13141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00  004  005   01   02  025   03   04  047   05  ...  zip  zippo  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...   \n",
       "12786  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "12787  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "12788  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "12789  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "12790  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "\n",
       "       zombie  zone  zoning  zoo  zuckerberg  zuckerbergs  zvisa  ʺmore  \n",
       "0         0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "1         0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "2         0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "3         0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "4         0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "...       ...   ...     ...  ...         ...          ...    ...    ...  \n",
       "12786     0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "12787     0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "12788     0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "12789     0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "12790     0.0   0.0     0.0  0.0         0.0          0.0    0.0    0.0  \n",
       "\n",
       "[12791 rows x 13141 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a matrix with the TF-IDF values\n",
    "X_tfidf_df = pd.DataFrame(X_tfidf.toarray())\n",
    "\n",
    "# Add column names\n",
    "X_tfidf_df.columns = tfidf_vect.get_feature_names()\n",
    "\n",
    "\n",
    "X_tfidf_df #product of all of the preprocessing\n",
    "\n",
    "# NOTE, in the end this was found to be too many features and so this TF-IDF section was dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject(s)</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Speaker_Job</th>\n",
       "      <th>State</th>\n",
       "      <th>Party</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>0</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12786</th>\n",
       "      <td>energy,oil-spill,trade</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>a press conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>candidates-biography</td>\n",
       "      <td>hillary-clinton</td>\n",
       "      <td>Presidential candidate</td>\n",
       "      <td>New York</td>\n",
       "      <td>democrat</td>\n",
       "      <td>a speech on the economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>health-care</td>\n",
       "      <td>campaign-defend-america</td>\n",
       "      <td>0</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>none</td>\n",
       "      <td>a television ad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12789</th>\n",
       "      <td>health-care</td>\n",
       "      <td>americans-united-change</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>an Internet ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12790</th>\n",
       "      <td>candidates-biography,infrastructure</td>\n",
       "      <td>rudy-giuliani</td>\n",
       "      <td>Attorney</td>\n",
       "      <td>New York</td>\n",
       "      <td>republican</td>\n",
       "      <td>comments on NBC's \"Meet the Press\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12791 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Subject(s)                  Speaker  \\\n",
       "0                                 abortion             dwayne-bohac   \n",
       "1       energy,history,job-accomplishments           scott-surovell   \n",
       "2                           foreign-policy             barack-obama   \n",
       "3                              health-care             blog-posting   \n",
       "4                             economy,jobs            charlie-crist   \n",
       "...                                    ...                      ...   \n",
       "12786               energy,oil-spill,trade             barack-obama   \n",
       "12787                 candidates-biography          hillary-clinton   \n",
       "12788                          health-care  campaign-defend-america   \n",
       "12789                          health-care  americans-united-change   \n",
       "12790  candidates-biography,infrastructure            rudy-giuliani   \n",
       "\n",
       "                  Speaker_Job             State       Party  \\\n",
       "0        State representative             Texas  republican   \n",
       "1              State delegate          Virginia    democrat   \n",
       "2                   President          Illinois    democrat   \n",
       "3                           0                 0        none   \n",
       "4                           0           Florida    democrat   \n",
       "...                       ...               ...         ...   \n",
       "12786               President          Illinois    democrat   \n",
       "12787  Presidential candidate          New York    democrat   \n",
       "12788                       0  Washington, D.C.        none   \n",
       "12789                       0                 0        none   \n",
       "12790                Attorney          New York  republican   \n",
       "\n",
       "                                  Context  \n",
       "0                                a mailer  \n",
       "1                         a floor speech.  \n",
       "2                                  Denver  \n",
       "3                          a news release  \n",
       "4                     an interview on CNN  \n",
       "...                                   ...  \n",
       "12786                  a press conference  \n",
       "12787             a speech on the economy  \n",
       "12788                     a television ad  \n",
       "12789                     an Internet ad.  \n",
       "12790  comments on NBC's \"Meet the Press\"  \n",
       "\n",
       "[12791 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use one hot encoding to convert categorical values into numerical values\n",
    "# First remove the columns we won't use\n",
    "hot_coding_data = df.copy()\n",
    "hot_coding_data = hot_coding_data.drop(columns = ['Statement_ID', 'Label', 'Statement', \n",
    "                                                  'Barely_True_History', 'False_History', \n",
    "                                                  'Half_True_History','Mostly_True_History',\n",
    "                                                  'Pants_On_Fire_History'])\n",
    "\n",
    "hot_coding_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put all of the columns into numerical values using one hot encoding.\n",
    "hot_coding_data = pd.get_dummies(hot_coding_data, columns=['Subject(s)'], prefix = '', drop_first = False)\n",
    "hot_coding_data = pd.get_dummies(hot_coding_data, columns=['Speaker'], prefix = '', drop_first = False)\n",
    "hot_coding_data = pd.get_dummies(hot_coding_data, columns=['Speaker_Job'], prefix = '', drop_first = False)\n",
    "hot_coding_data = pd.get_dummies(hot_coding_data, columns=['State'], prefix = '', drop_first = False)\n",
    "hot_coding_data = pd.get_dummies(hot_coding_data, columns=['Party'], prefix = '', drop_first = False)\n",
    "hot_coding_data = pd.get_dummies(hot_coding_data, columns=['Context'], prefix = '', drop_first = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_0.0</th>\n",
       "      <th>_Alcohol</th>\n",
       "      <th>_Alcohol,animals,children,crime</th>\n",
       "      <th>_Alcohol,campaign-finance,ethics,public-service</th>\n",
       "      <th>_Alcohol,candidates-biography</th>\n",
       "      <th>_Alcohol,candidates-biography,crime</th>\n",
       "      <th>_Alcohol,children</th>\n",
       "      <th>_Alcohol,children,crime,public-health,public-safety</th>\n",
       "      <th>_Alcohol,children,drugs,marijuana</th>\n",
       "      <th>_Alcohol,city-government</th>\n",
       "      <th>...</th>\n",
       "      <th>_website posting.</th>\n",
       "      <th>_weekly Senate Republican radio address</th>\n",
       "      <th>_while interviewing Donald Trump in Austin</th>\n",
       "      <th>_whylarrywhy.com</th>\n",
       "      <th>_women's conference session</th>\n",
       "      <th>_written testimony at a House hearing</th>\n",
       "      <th>_written testimony to a Wisconsin Senate committee</th>\n",
       "      <th>_x</th>\n",
       "      <th>_yard signs posted anonymously opposing a proposed office park redevelopment in Northwest Austin</th>\n",
       "      <th>_“Voters Guide,” League of Women Voters of the Austin Area.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12786</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12789</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12790</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12791 rows × 14455 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       _0.0  _Alcohol  _Alcohol,animals,children,crime  \\\n",
       "0         0         0                                0   \n",
       "1         0         0                                0   \n",
       "2         0         0                                0   \n",
       "3         0         0                                0   \n",
       "4         0         0                                0   \n",
       "...     ...       ...                              ...   \n",
       "12786     0         0                                0   \n",
       "12787     0         0                                0   \n",
       "12788     0         0                                0   \n",
       "12789     0         0                                0   \n",
       "12790     0         0                                0   \n",
       "\n",
       "       _Alcohol,campaign-finance,ethics,public-service  \\\n",
       "0                                                    0   \n",
       "1                                                    0   \n",
       "2                                                    0   \n",
       "3                                                    0   \n",
       "4                                                    0   \n",
       "...                                                ...   \n",
       "12786                                                0   \n",
       "12787                                                0   \n",
       "12788                                                0   \n",
       "12789                                                0   \n",
       "12790                                                0   \n",
       "\n",
       "       _Alcohol,candidates-biography  _Alcohol,candidates-biography,crime  \\\n",
       "0                                  0                                    0   \n",
       "1                                  0                                    0   \n",
       "2                                  0                                    0   \n",
       "3                                  0                                    0   \n",
       "4                                  0                                    0   \n",
       "...                              ...                                  ...   \n",
       "12786                              0                                    0   \n",
       "12787                              0                                    0   \n",
       "12788                              0                                    0   \n",
       "12789                              0                                    0   \n",
       "12790                              0                                    0   \n",
       "\n",
       "       _Alcohol,children  _Alcohol,children,crime,public-health,public-safety  \\\n",
       "0                      0                                                  0     \n",
       "1                      0                                                  0     \n",
       "2                      0                                                  0     \n",
       "3                      0                                                  0     \n",
       "4                      0                                                  0     \n",
       "...                  ...                                                ...     \n",
       "12786                  0                                                  0     \n",
       "12787                  0                                                  0     \n",
       "12788                  0                                                  0     \n",
       "12789                  0                                                  0     \n",
       "12790                  0                                                  0     \n",
       "\n",
       "       _Alcohol,children,drugs,marijuana  _Alcohol,city-government  ...  \\\n",
       "0                                      0                         0  ...   \n",
       "1                                      0                         0  ...   \n",
       "2                                      0                         0  ...   \n",
       "3                                      0                         0  ...   \n",
       "4                                      0                         0  ...   \n",
       "...                                  ...                       ...  ...   \n",
       "12786                                  0                         0  ...   \n",
       "12787                                  0                         0  ...   \n",
       "12788                                  0                         0  ...   \n",
       "12789                                  0                         0  ...   \n",
       "12790                                  0                         0  ...   \n",
       "\n",
       "       _website posting.  _weekly Senate Republican radio address  \\\n",
       "0                      0                                        0   \n",
       "1                      0                                        0   \n",
       "2                      0                                        0   \n",
       "3                      0                                        0   \n",
       "4                      0                                        0   \n",
       "...                  ...                                      ...   \n",
       "12786                  0                                        0   \n",
       "12787                  0                                        0   \n",
       "12788                  0                                        0   \n",
       "12789                  0                                        0   \n",
       "12790                  0                                        0   \n",
       "\n",
       "       _while interviewing Donald Trump in Austin  _whylarrywhy.com  \\\n",
       "0                                               0                 0   \n",
       "1                                               0                 0   \n",
       "2                                               0                 0   \n",
       "3                                               0                 0   \n",
       "4                                               0                 0   \n",
       "...                                           ...               ...   \n",
       "12786                                           0                 0   \n",
       "12787                                           0                 0   \n",
       "12788                                           0                 0   \n",
       "12789                                           0                 0   \n",
       "12790                                           0                 0   \n",
       "\n",
       "       _women's conference session  _written testimony at a House hearing  \\\n",
       "0                                0                                      0   \n",
       "1                                0                                      0   \n",
       "2                                0                                      0   \n",
       "3                                0                                      0   \n",
       "4                                0                                      0   \n",
       "...                            ...                                    ...   \n",
       "12786                            0                                      0   \n",
       "12787                            0                                      0   \n",
       "12788                            0                                      0   \n",
       "12789                            0                                      0   \n",
       "12790                            0                                      0   \n",
       "\n",
       "       _written testimony to a Wisconsin Senate committee  _x  \\\n",
       "0                                                      0    0   \n",
       "1                                                      0    0   \n",
       "2                                                      0    0   \n",
       "3                                                      0    0   \n",
       "4                                                      0    0   \n",
       "...                                                  ...   ..   \n",
       "12786                                                  0    0   \n",
       "12787                                                  0    0   \n",
       "12788                                                  0    0   \n",
       "12789                                                  0    0   \n",
       "12790                                                  0    0   \n",
       "\n",
       "       _yard signs posted anonymously opposing a proposed office park redevelopment in Northwest Austin  \\\n",
       "0                                                      0                                                  \n",
       "1                                                      0                                                  \n",
       "2                                                      0                                                  \n",
       "3                                                      0                                                  \n",
       "4                                                      0                                                  \n",
       "...                                                  ...                                                  \n",
       "12786                                                  0                                                  \n",
       "12787                                                  0                                                  \n",
       "12788                                                  0                                                  \n",
       "12789                                                  0                                                  \n",
       "12790                                                  0                                                  \n",
       "\n",
       "       _“Voters Guide,” League of Women Voters of the Austin Area.  \n",
       "0                                                      0            \n",
       "1                                                      0            \n",
       "2                                                      0            \n",
       "3                                                      0            \n",
       "4                                                      0            \n",
       "...                                                  ...            \n",
       "12786                                                  0            \n",
       "12787                                                  0            \n",
       "12788                                                  0            \n",
       "12789                                                  0            \n",
       "12790                                                  0            \n",
       "\n",
       "[12791 rows x 14455 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE, this, like the TF-IDF features, was found to be too large and so was dropped from the final version\n",
    "hot_coding_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label                                          Statement\n",
       "0        false  Says the Annies List political group supports ...\n",
       "1    half-true  When did the decline of coal start? It started...\n",
       "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...\n",
       "3        false  Health care reform legislation is likely to ma...\n",
       "4    half-true  The economic turnaround started at the end of ..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[['Label', 'Statement']].copy()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the functions needed for removing the features as seen below\n",
    "\n",
    "def no_of_stopwords(x):\n",
    "    sw = nltk.corpus.stopwords.words('english') \n",
    "    word_tokens = nltk.sent_tokenize(x)\n",
    "    stopwords_x = [w for w in word_tokens if w in sw]\n",
    "    return len(stopwords_x)\n",
    "\n",
    "\n",
    "def count_punc(x):\n",
    "    punctuations= string.punctuation\n",
    "    d=dict()\n",
    "    for i in punctuations:\n",
    "        d[str(i)+' count']=x.count(i)\n",
    "    count = 0\n",
    "    for i in d:\n",
    "        count += d[i]\n",
    "    return count\n",
    "\n",
    "def count_words_in_quotes(x):\n",
    "    add = re.findall(r'[\"](.*?)[\"]',x)\n",
    "    count=0\n",
    "    if add is None:\n",
    "        return 0\n",
    "    else:\n",
    "        for i in add:\n",
    "            t=i#[1:-1]\n",
    "            #print(\"t is: \", t)\n",
    "            count+=len(t) - t.count(\" \")\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First ten features\n",
    "data['body_len'] = data['Statement'].apply(lambda x: len(x) - x.count(\" \"))          # First Feature - number of letters\n",
    "data['no_of_words'] = data['Statement'].apply(lambda x: len(x.split()))              # Second Feature - number of words\n",
    "data['no_of_sent'] = data['Statement'].apply(lambda x: len(nltk.sent_tokenize(x)))   # Third Feature - number of sentences\n",
    "data['no_of_unique_words'] = data['Statement'].apply(lambda x: len(set(x.split())))  # Fourth Feature - # of unique words\n",
    "data['no_of_stopwords'] = data['Statement'].apply(lambda x: no_of_stopwords(x))      # Fifth Feature - # of stopwords\n",
    "data['avg_word_len'] = data['body_len']/data['no_of_words']                          # Sixth Feature - avg word length\n",
    "data['avg_%_stopwords'] = data['no_of_stopwords']/data['no_of_words']                # Seventh Feature - avg % being stopwords\n",
    "data['no_of_punc'] = data['Statement'].apply(lambda x: count_punc(x))                # Eight Feature - amount of punctuation\n",
    "data['words_in_quote'] = data['Statement'].apply(lambda x: count_words_in_quotes(x)) # Ninth Feature - # of words in quotes\n",
    "data['%_of_unique_words'] = data['no_of_unique_words']/data['no_of_words']           # Tenth Feature - % of words that are unique\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# This box is preparing the data to be run through the function that determines the types of words in each entry\n",
    "# for example if there are nouns or proper nouns or verbs in a particular statement.\n",
    "\n",
    "df_token = df_clean[['body_text_tokenized']]\n",
    "\n",
    "tok = df_token.to_numpy()\n",
    "\n",
    "hold = ['Hello,', \"my\", \"name\", \"is\", \"Chris\"]\n",
    "\n",
    "# Changes all of the numbers into strings\n",
    "for text in tok:\n",
    "    #print(text)\n",
    "    for w in text:\n",
    "        for word in w:\n",
    "            #print(type(word))\n",
    "            if word.isdigit():\n",
    "                num = int(word)\n",
    "entries = {}\n",
    "entries[0] = {}\n",
    "\n",
    "for i in range(0, len(tok)):\n",
    "    tagged = nltk.pos_tag([q for q in tok[i][0] if q])\n",
    "    counts = Counter(tag for word, tag in tagged)\n",
    "    entries[i] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VBZ</th>\n",
       "      <th>DT</th>\n",
       "      <th>NNS</th>\n",
       "      <th>VBP</th>\n",
       "      <th>JJ</th>\n",
       "      <th>NN</th>\n",
       "      <th>IN</th>\n",
       "      <th>WRB</th>\n",
       "      <th>VBD</th>\n",
       "      <th>PRP</th>\n",
       "      <th>...</th>\n",
       "      <th>NNP</th>\n",
       "      <th>WDT</th>\n",
       "      <th>MD</th>\n",
       "      <th>PDT</th>\n",
       "      <th>EX</th>\n",
       "      <th>RBS</th>\n",
       "      <th>$</th>\n",
       "      <th>WP$</th>\n",
       "      <th>FW</th>\n",
       "      <th>UH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12786</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12789</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12790</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12791 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       VBZ   DT  NNS  VBP   JJ    NN   IN  WRB  VBD  PRP  ...  NNP  WDT   MD  \\\n",
       "0      2.0  1.0  2.0  1.0  1.0   3.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1      0.0  1.0  0.0  0.0  2.0   7.0  3.0  2.0  5.0  1.0  ...  0.0  0.0  0.0   \n",
       "2      1.0  2.0  0.0  0.0  1.0   7.0  5.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3      1.0  0.0  1.0  0.0  2.0   6.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4      0.0  2.0  0.0  0.0  1.0   3.0  2.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
       "...    ...  ...  ...  ...  ...   ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "12786  0.0  3.0  1.0  0.0  1.0   4.0  6.0  0.0  2.0  1.0  ...  0.0  0.0  0.0   \n",
       "12787  2.0  0.0  2.0  0.0  0.0   2.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "12788  0.0  1.0  1.0  1.0  1.0   6.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "12789  2.0  4.0  1.0  2.0  3.0  10.0  1.0  0.0  0.0  2.0  ...  0.0  1.0  0.0   \n",
       "12790  2.0  3.0  0.0  0.0  2.0   8.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "       PDT   EX  RBS    $  WP$   FW   UH  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "12786  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12787  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12788  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12789  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12790  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[12791 rows x 34 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_structure = pd.DataFrame.from_dict(entries) # make a new dataframe\n",
    "# swap the rows and columns\n",
    "word_structure = word_structure.T\n",
    "# replace NAN\n",
    "word_structure = word_structure.fillna(0.0)\n",
    "\n",
    "word_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features 11 - 20\n",
    "# Second ten features\n",
    "data['no_of_numerical'] = data['Statement'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))  # 11th feature amount of numerical values\n",
    "data['upper_case_words'] = data['Statement'].apply(lambda x: len([x for x in x.split() if x.isupper()])) # 12th feature amount of uppercase words\n",
    "data['avg_sentence_length'] = data['no_of_words']/data['no_of_sent']                                     # 13th feature average sentence length\n",
    "data['no_of_nouns'] = word_structure['NN'] + word_structure['NNS']                                       # 14th feature amount of nouns in entry\n",
    "data['proper_nouns'] = word_structure['NNP'] + word_structure['NNPS']                                    # 15th feature number of proper nouns\n",
    "data['no_of_base_verbs'] = word_structure['VB']                                                          # 16th feature number of base verbs\n",
    "data['past_tense_verbs'] = word_structure['VBD']                                                         # 17th feature number of past tense verbs\n",
    "data['verb_participle'] = word_structure['VBG'] + word_structure['VBN']                                  # 18th feature number of participle verbs\n",
    "data['no_of_adj'] = word_structure['JJ'] + word_structure['JJR'] + word_structure['JJS']                 # 19th feature number of adjectives\n",
    "data['personal_pronouns'] = word_structure['PRP']                                                        # 20th feature number of personal pronouns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features 21 - 30\n",
    "# Third ten features\n",
    "data['no_of_particles'] = word_structure['RP']                                               # 21st feature, number of particles\n",
    "data['no_of_prepositions'] = word_structure['IN']                                            # 22nd feature, number of prepositions\n",
    "data['no_of_foreign_words'] = word_structure['FW']                                           # 23rd feature, number of foreign words \n",
    "data['no_of_adverbs'] = word_structure['RB'] + word_structure['RBR'] + word_structure['RBS'] # 24th feature, number of adverbs\n",
    "data['pos_pronouns'] = word_structure['PRP$']                                                # 25th feature, number of possessive pronouns\n",
    "data['no_of_numerals'] = word_structure['CD']                                                # 26th feature, number of numbers\n",
    "data['no_of_interjections'] = word_structure['UH']                                           # 27th feature, number of interjections\n",
    "data['no_of_determiners'] = word_structure['DT']                                             # 28th feature, number of determiners\n",
    "data['no_of_predeterminers'] = word_structure['PDT']                                         # 29th feature, number of pre-determiners\n",
    "# 30th feature, number of wh- question words\n",
    "data['WH_questions'] = word_structure['WDT'] + word_structure['WP'] + word_structure['WP$'] + word_structure['WRB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features 31 - 40\n",
    "# Fourth ten features\n",
    "data['no_long_words'] = data['Statement'].apply(lambda x: len([x for x in x.split()if x and len(x) > 6]))   # feature 31, number of \"long\" words\n",
    "data['no_short_words'] = data['Statement'].apply(lambda x: len([x for x in x.split()if x and len(x) <= 6])) # feature 32, number of \"short\" words\n",
    "data['no_very_short_words'] = data['Statement'].apply(lambda x: len([x for x in x.split()if x and len(x) < 3])) # feature 33, number of \"very short\" words\n",
    "data['no_very_long_words'] = data['Statement'].apply(lambda x: len([x for x in x.split()if x and len(x) > 9])) # feature 34, number of \"very long\" words\n",
    "data['percent_long_words'] = data['no_long_words']/data['no_of_words']                                         # feature 35, % of long words\n",
    "data['percent_very_long_words'] = data['no_very_long_words']/data['no_of_words']                               # feature 36, % very long words\n",
    "data['percent_very_short_words'] = data['no_very_short_words']/data['no_of_words']                             # feature 37, % very short words\n",
    "data['avg_long_word_per_sentence'] = data['no_long_words']/data['no_of_sent']                                  # feature 38, number of long words in sentences\n",
    "data['%_nouns'] = data['no_of_nouns']/data['no_of_words']                                                      # feature 39, % that is nouns\n",
    "data['%_adjectives'] = data['no_of_adj']/data['no_of_words']                                                   # feature 40, % that is adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>body_len</th>\n",
       "      <th>no_of_words</th>\n",
       "      <th>no_of_sent</th>\n",
       "      <th>no_of_unique_words</th>\n",
       "      <th>no_of_stopwords</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>avg_%_stopwords</th>\n",
       "      <th>no_of_punc</th>\n",
       "      <th>...</th>\n",
       "      <th>%_particles</th>\n",
       "      <th>%_prepositions</th>\n",
       "      <th>%_adverbs</th>\n",
       "      <th>%_WH_questions</th>\n",
       "      <th>%_verbs</th>\n",
       "      <th>%_personal_pronouns</th>\n",
       "      <th>%_proper_nouns</th>\n",
       "      <th>%_numerals</th>\n",
       "      <th>%_in_quotes</th>\n",
       "      <th>%_determiners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>72</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>118</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>87</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>4.578947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.684211</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12786</th>\n",
       "      <td>half-true</td>\n",
       "      <td>For the first time in more than a decade, impo...</td>\n",
       "      <td>85</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Says Donald Trump has bankrupted his companies...</td>\n",
       "      <td>69</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>true</td>\n",
       "      <td>John McCain and George Bush have \"absolutely n...</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12789</th>\n",
       "      <td>false</td>\n",
       "      <td>A new poll shows 62 percent support the presid...</td>\n",
       "      <td>164</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4.969697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12790</th>\n",
       "      <td>barely-true</td>\n",
       "      <td>No one claims the report vindicating New Jerse...</td>\n",
       "      <td>88</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>5.176471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12791 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Label                                          Statement  \\\n",
       "0            false  Says the Annies List political group supports ...   \n",
       "1        half-true  When did the decline of coal start? It started...   \n",
       "2      mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3            false  Health care reform legislation is likely to ma...   \n",
       "4        half-true  The economic turnaround started at the end of ...   \n",
       "...            ...                                                ...   \n",
       "12786    half-true  For the first time in more than a decade, impo...   \n",
       "12787  mostly-true  Says Donald Trump has bankrupted his companies...   \n",
       "12788         true  John McCain and George Bush have \"absolutely n...   \n",
       "12789        false  A new poll shows 62 percent support the presid...   \n",
       "12790  barely-true  No one claims the report vindicating New Jerse...   \n",
       "\n",
       "       body_len  no_of_words  no_of_sent  no_of_unique_words  no_of_stopwords  \\\n",
       "0            72           11           1                  11                0   \n",
       "1           118           24           2                  23                0   \n",
       "2            87           19           1                  18                0   \n",
       "3            67           12           1                  12                0   \n",
       "4            45           10           1                  10                0   \n",
       "...         ...          ...         ...                 ...              ...   \n",
       "12786        85           20           1                  19                0   \n",
       "12787        69           14           1                  13                0   \n",
       "12788        68           13           1                  13                0   \n",
       "12789       164           33           2                  29                0   \n",
       "12790        88           17           2                  16                0   \n",
       "\n",
       "       avg_word_len  avg_%_stopwords  no_of_punc  ...  %_particles  \\\n",
       "0          6.545455              0.0           2  ...     0.000000   \n",
       "1          4.916667              0.0           5  ...     0.041667   \n",
       "2          4.578947              0.0           3  ...     0.000000   \n",
       "3          5.583333              0.0           1  ...     0.000000   \n",
       "4          4.500000              0.0           1  ...     0.000000   \n",
       "...             ...              ...         ...  ...          ...   \n",
       "12786      4.250000              0.0           4  ...     0.000000   \n",
       "12787      4.928571              0.0           2  ...     0.000000   \n",
       "12788      5.230769              0.0           3  ...     0.000000   \n",
       "12789      4.969697              0.0           6  ...     0.000000   \n",
       "12790      5.176471              0.0           2  ...     0.000000   \n",
       "\n",
       "       %_prepositions  %_adverbs  %_WH_questions   %_verbs  \\\n",
       "0            0.090909   0.000000        0.000000  0.000000   \n",
       "1            0.125000   0.000000        0.083333  0.250000   \n",
       "2            0.263158   0.000000        0.000000  0.052632   \n",
       "3            0.000000   0.000000        0.000000  0.083333   \n",
       "4            0.200000   0.000000        0.000000  0.100000   \n",
       "...               ...        ...             ...       ...   \n",
       "12786        0.300000   0.000000        0.000000  0.100000   \n",
       "12787        0.000000   0.285714        0.000000  0.000000   \n",
       "12788        0.076923   0.076923        0.000000  0.000000   \n",
       "12789        0.030303   0.000000        0.030303  0.030303   \n",
       "12790        0.058824   0.000000        0.000000  0.000000   \n",
       "\n",
       "       %_personal_pronouns  %_proper_nouns  %_numerals  %_in_quotes  \\\n",
       "0                 0.000000             0.0    0.000000     0.000000   \n",
       "1                 0.041667             0.0    0.000000     0.000000   \n",
       "2                 0.000000             0.0    0.000000     2.684211   \n",
       "3                 0.000000             0.0    0.000000     0.000000   \n",
       "4                 0.000000             0.0    0.000000     0.000000   \n",
       "...                    ...             ...         ...          ...   \n",
       "12786             0.050000             0.0    0.000000     0.000000   \n",
       "12787             0.000000             0.0    0.071429     0.000000   \n",
       "12788             0.000000             0.0    0.000000     3.000000   \n",
       "12789             0.060606             0.0    0.030303     0.000000   \n",
       "12790             0.000000             0.0    0.000000     0.000000   \n",
       "\n",
       "       %_determiners  \n",
       "0           0.090909  \n",
       "1           0.041667  \n",
       "2           0.105263  \n",
       "3           0.000000  \n",
       "4           0.200000  \n",
       "...              ...  \n",
       "12786       0.150000  \n",
       "12787       0.000000  \n",
       "12788       0.076923  \n",
       "12789       0.121212  \n",
       "12790       0.176471  \n",
       "\n",
       "[12791 rows x 52 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features 41 - 50\n",
    "# Fifth ten features\n",
    "data['%_particles'] = data['no_of_particles']/data['no_of_words']                               # feature 41, % that is particles\n",
    "data['%_prepositions'] = data['no_of_prepositions']/data['no_of_words']                         # feature 42, % that is prepositions\n",
    "data['%_adverbs'] = data['no_of_adverbs']/data['no_of_words']                                   # feature 43, % that is adverbs\n",
    "data['%_WH_questions'] = data['WH_questions']/data['no_of_words']                               # feature 44, % that is WH questions\n",
    "data['%_verbs'] = (data['no_of_base_verbs'] + data['past_tense_verbs'])/data['no_of_words']     # feature 45, % that are verbs\n",
    "data['%_personal_pronouns'] = data['personal_pronouns']/data['no_of_words']                     # feature 46, % that are personal pronouns\n",
    "data['%_proper_nouns'] = data['proper_nouns']/data['no_of_words']                               # feature 47, % that are proper pronouns\n",
    "data['%_numerals'] = data['no_of_numerals']/data['no_of_words']                                 # feature 48, % that are numbers\n",
    "data['%_in_quotes'] = data['words_in_quote']/data['no_of_words']                                # feature 49, % of words that are in quotes\n",
    "data['%_determiners'] = data['no_of_determiners']/data['no_of_words']                           # feature 50, % of words that are determiners\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Data Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section was done as a replacement for the hot_coding_data section used previously\n",
    "\n",
    "data_hold = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace republican with 2, Democrat with 1, and none/independent with 8\n",
    "# Replace third party with 3\n",
    "# Replace official with 4, organization with 5\n",
    "# Replace journalist/journalist entertainers with 6\n",
    "# Replace other with 7\n",
    "\n",
    "data_hold['Party'] = data_hold['Party'].replace(['republican', 'democrat','none', 'independent'],[2, 1, 8, 8])\n",
    "data_hold['Party'] = data_hold['Party'].replace(['libertarian', 'green', 'Moderate', 'democratic-farmer-labor',\n",
    "                                                 'ocean-state-tea-party-action', 'constitution-party',\n",
    "                                                'labor-leader', 'tea-party-member'], 3)\n",
    "data_hold['Party'] = data_hold['Party'].replace(['state-official', 'education-official', 'organization', \n",
    "                                                 'government-body'],[4,4,5,4])\n",
    "data_hold['Party'] = data_hold['Party'].replace(['columnist', 'talk-show-host', 'newsmaker', 'journalist'],6)\n",
    "data_hold['Party'] = data_hold['Party'].replace(['activist', 'business-leader', 'liberal-party-canada',\n",
    "                                                 'county-commissioner'],7)\n",
    "extracted_col = data_hold['Party']\n",
    "data = data.join(extracted_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add history of the speaker to the features\n",
    "# Barely_True_History has only integers, 30 unique values\n",
    "# False_History has only integers, 30 unique values\n",
    "# Half_True_History has only integers, 29 unique values\n",
    "# Mostly_True_History has only integers, 27 unique values\n",
    "# Pants_On_Fire_History has only integers, 20 unique values\n",
    "\n",
    "extracted_cols = data_hold[['Barely_True_History', 'False_History', 'Half_True_History', \n",
    "                            'Mostly_True_History', 'Pants_On_Fire_History']]\n",
    "data=data.join(extracted_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below features were removed as they caused overfitting of the Bi-LSTM network\n",
    "\n",
    "# data['Speaker'] = pd.factorize(data_hold.Speaker)[0] + 1 # 3310 unique entries\n",
    "# data['State'] = pd.factorize(data_hold.State)[0] + 1 # 86 unique entries (at least)\n",
    "\n",
    "# data_hold['Subject'] = data_hold['Subject(s)']\n",
    "# # data_hold = data_hold.drop(['Subject(s)'])\n",
    "# data['Subject'] = pd.factorize(data_hold['Subject'])[0] + 1 # 4535 unique entries\n",
    "\n",
    "# data['Speaker_Job'] = pd.factorize(data_hold['Speaker_Job'])[0] + 1 # 1356 unique entries\n",
    "# data['Context'] = pd.factorize(data_hold['Context'])[0] + 1 # 5143 unique entries\n",
    "# print(data_hold['Speaker'].nunique())\n",
    "\n",
    "# print(\"Speaker: \",data['Speaker'].nunique())\n",
    "# print(\"State: \",data['State'].nunique())\n",
    "# print(\"Subject: \",data['Subject'].nunique())\n",
    "# print(\"Speaker_job: \",data['Speaker_Job'].nunique())\n",
    "# print(\"Context: \",data['Context'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>body_len</th>\n",
       "      <th>no_of_words</th>\n",
       "      <th>no_of_sent</th>\n",
       "      <th>no_of_unique_words</th>\n",
       "      <th>no_of_stopwords</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>avg_%_stopwords</th>\n",
       "      <th>no_of_punc</th>\n",
       "      <th>...</th>\n",
       "      <th>%_proper_nouns</th>\n",
       "      <th>%_numerals</th>\n",
       "      <th>%_in_quotes</th>\n",
       "      <th>%_determiners</th>\n",
       "      <th>Party</th>\n",
       "      <th>Barely_True_History</th>\n",
       "      <th>False_History</th>\n",
       "      <th>Half_True_History</th>\n",
       "      <th>Mostly_True_History</th>\n",
       "      <th>Pants_On_Fire_History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>72</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>118</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>87</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>4.578947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.684211</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12786</th>\n",
       "      <td>half-true</td>\n",
       "      <td>For the first time in more than a decade, impo...</td>\n",
       "      <td>85</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Says Donald Trump has bankrupted his companies...</td>\n",
       "      <td>69</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>true</td>\n",
       "      <td>John McCain and George Bush have \"absolutely n...</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12789</th>\n",
       "      <td>false</td>\n",
       "      <td>A new poll shows 62 percent support the presid...</td>\n",
       "      <td>164</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4.969697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12790</th>\n",
       "      <td>barely-true</td>\n",
       "      <td>No one claims the report vindicating New Jerse...</td>\n",
       "      <td>88</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>5.176471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12791 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Label                                          Statement  \\\n",
       "0            false  Says the Annies List political group supports ...   \n",
       "1        half-true  When did the decline of coal start? It started...   \n",
       "2      mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3            false  Health care reform legislation is likely to ma...   \n",
       "4        half-true  The economic turnaround started at the end of ...   \n",
       "...            ...                                                ...   \n",
       "12786    half-true  For the first time in more than a decade, impo...   \n",
       "12787  mostly-true  Says Donald Trump has bankrupted his companies...   \n",
       "12788         true  John McCain and George Bush have \"absolutely n...   \n",
       "12789        false  A new poll shows 62 percent support the presid...   \n",
       "12790  barely-true  No one claims the report vindicating New Jerse...   \n",
       "\n",
       "       body_len  no_of_words  no_of_sent  no_of_unique_words  no_of_stopwords  \\\n",
       "0            72           11           1                  11                0   \n",
       "1           118           24           2                  23                0   \n",
       "2            87           19           1                  18                0   \n",
       "3            67           12           1                  12                0   \n",
       "4            45           10           1                  10                0   \n",
       "...         ...          ...         ...                 ...              ...   \n",
       "12786        85           20           1                  19                0   \n",
       "12787        69           14           1                  13                0   \n",
       "12788        68           13           1                  13                0   \n",
       "12789       164           33           2                  29                0   \n",
       "12790        88           17           2                  16                0   \n",
       "\n",
       "       avg_word_len  avg_%_stopwords  no_of_punc  ...  %_proper_nouns  \\\n",
       "0          6.545455              0.0           2  ...             0.0   \n",
       "1          4.916667              0.0           5  ...             0.0   \n",
       "2          4.578947              0.0           3  ...             0.0   \n",
       "3          5.583333              0.0           1  ...             0.0   \n",
       "4          4.500000              0.0           1  ...             0.0   \n",
       "...             ...              ...         ...  ...             ...   \n",
       "12786      4.250000              0.0           4  ...             0.0   \n",
       "12787      4.928571              0.0           2  ...             0.0   \n",
       "12788      5.230769              0.0           3  ...             0.0   \n",
       "12789      4.969697              0.0           6  ...             0.0   \n",
       "12790      5.176471              0.0           2  ...             0.0   \n",
       "\n",
       "       %_numerals  %_in_quotes  %_determiners  Party  Barely_True_History  \\\n",
       "0        0.000000     0.000000       0.090909    2.0                  0.0   \n",
       "1        0.000000     0.000000       0.041667    1.0                  0.0   \n",
       "2        0.000000     2.684211       0.105263    1.0                 70.0   \n",
       "3        0.000000     0.000000       0.000000    8.0                  7.0   \n",
       "4        0.000000     0.000000       0.200000    1.0                 15.0   \n",
       "...           ...          ...            ...    ...                  ...   \n",
       "12786    0.000000     0.000000       0.150000    1.0                 70.0   \n",
       "12787    0.071429     0.000000       0.000000    1.0                 40.0   \n",
       "12788    0.000000     3.000000       0.076923    8.0                  0.0   \n",
       "12789    0.030303     0.000000       0.121212    8.0                  1.0   \n",
       "12790    0.000000     0.000000       0.176471    2.0                  9.0   \n",
       "\n",
       "       False_History  Half_True_History  Mostly_True_History  \\\n",
       "0                1.0                0.0                  0.0   \n",
       "1                0.0                1.0                  1.0   \n",
       "2               71.0              160.0                163.0   \n",
       "3               19.0                3.0                  5.0   \n",
       "4                9.0               20.0                 19.0   \n",
       "...              ...                ...                  ...   \n",
       "12786           71.0              160.0                163.0   \n",
       "12787           29.0               69.0                 76.0   \n",
       "12788            1.0                0.0                  2.0   \n",
       "12789            4.0                4.0                  1.0   \n",
       "12790           11.0               10.0                  7.0   \n",
       "\n",
       "       Pants_On_Fire_History  \n",
       "0                        0.0  \n",
       "1                        0.0  \n",
       "2                        9.0  \n",
       "3                       44.0  \n",
       "4                        2.0  \n",
       "...                      ...  \n",
       "12786                    9.0  \n",
       "12787                    7.0  \n",
       "12788                    0.0  \n",
       "12789                    0.0  \n",
       "12790                    3.0  \n",
       "\n",
       "[12791 rows x 58 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the random forest imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "data_train = data.drop(columns = ['Label', 'Statement'])\n",
    "\n",
    "df_features = data_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the datasets back into training, testing and validation\n",
    "df_1 = df_features.iloc[:10240,:]\n",
    "df_2 = df_features.iloc[10240:,:]\n",
    "\n",
    "testing = df_2.iloc[:1267,:]\n",
    "validate = df_2.iloc[1267:,:]\n",
    "testing = testing.reset_index()\n",
    "validate = validate.reset_index()\n",
    "\n",
    "\n",
    "testing = testing.drop(columns = ['index'])\n",
    "validate = validate.drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with 100 trees\n",
    "model = RandomForestClassifier(n_estimators=100, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features='sqrt')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on training data\n",
    "model.fit(df_1, train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Half_True_History</th>\n",
       "      <td>0.055577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mostly_True_History</th>\n",
       "      <td>0.055465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False_History</th>\n",
       "      <td>0.053487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barely_True_History</th>\n",
       "      <td>0.052218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pants_On_Fire_History</th>\n",
       "      <td>0.036548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_word_len</th>\n",
       "      <td>0.036057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_nouns</th>\n",
       "      <td>0.033392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_very_short_words</th>\n",
       "      <td>0.032311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_len</th>\n",
       "      <td>0.032271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_prepositions</th>\n",
       "      <td>0.031264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_long_words</th>\n",
       "      <td>0.031159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_adjectives</th>\n",
       "      <td>0.028834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_determiners</th>\n",
       "      <td>0.028488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_verbs</th>\n",
       "      <td>0.025907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_very_long_words</th>\n",
       "      <td>0.024643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <td>0.024298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_short_words</th>\n",
       "      <td>0.023421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_unique_words</th>\n",
       "      <td>0.021747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_words</th>\n",
       "      <td>0.021278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_nouns</th>\n",
       "      <td>0.020753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          importance\n",
       "Half_True_History           0.055577\n",
       "Mostly_True_History         0.055465\n",
       "False_History               0.053487\n",
       "Barely_True_History         0.052218\n",
       "Pants_On_Fire_History       0.036548\n",
       "avg_word_len                0.036057\n",
       "%_nouns                     0.033392\n",
       "percent_very_short_words    0.032311\n",
       "body_len                    0.032271\n",
       "%_prepositions              0.031264\n",
       "percent_long_words          0.031159\n",
       "%_adjectives                0.028834\n",
       "%_determiners               0.028488\n",
       "%_verbs                     0.025907\n",
       "percent_very_long_words     0.024643\n",
       "avg_sentence_length         0.024298\n",
       "no_short_words              0.023421\n",
       "no_of_unique_words          0.021747\n",
       "no_of_words                 0.021278\n",
       "no_of_nouns                 0.020753"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the most important features, and print them out in descending order of importance.\n",
    "\n",
    "feature_importances = pd.DataFrame(model.feature_importances_, index = df_1.columns,  \n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(max_features='sqrt'),\n",
       "                threshold=0.001)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin feature selection\n",
    "rf_model = SelectFromModel(model, threshold = 0.001)\n",
    "rf_model.fit(df_1, train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data to create a new dataset containing only the most important features\n",
    "# Note: We have to apply the transform to both the training X and test X data.\n",
    "rf_2_train = rf_model.transform(df_1)\n",
    "rf_2_test = rf_model.transform(testing)\n",
    "rf_2_valid = rf_model.transform(validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# function for running through the random forest model several times\n",
    "def forest():\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1) # n_jobs makes it go fast, random state increases the accuracy\n",
    "    \n",
    "    rf.fit(rf_2_train,train['Label'])\n",
    "    \n",
    "    # Actual class predictions\n",
    "    rf_model_t = rf.predict(rf_2_test)\n",
    "    rf_model_v = rf.predict(rf_2_valid)\n",
    "\n",
    "    # View accuracy score\n",
    "    rf_test_sc = accuracy_score(test['Label'], rf_model_t)\n",
    "    rf_valid_sc = accuracy_score(valid['Label'], rf_model_v)\n",
    "    \n",
    "    return rf_test_sc, rf_valid_sc\n",
    "\n",
    "# function for getting the average of several numbers\n",
    "def cal_average(num):\n",
    "    sum_num = 0\n",
    "    for t in num:\n",
    "        sum_num = sum_num + t           \n",
    "    if len(num) > 0:\n",
    "        avg = sum_num / len(num)\n",
    "    else: \n",
    "        avg = 0\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is:  0.44672454617206003\n",
      "Valid score is:  0.4369158878504673\n",
      "The non selected score is:  0.4230465666929755\n"
     ]
    }
   ],
   "source": [
    "# Train the random forest classifier 10 times and get the average score for both the test and valid data set.\n",
    "\n",
    "features_normal_t = []\n",
    "features_normal_v = []\n",
    "\n",
    "for i in range(10):\n",
    "    test_sc, valid_sc = forest()\n",
    "    features_normal_t.append(test_sc)\n",
    "    features_normal_v.append(valid_sc)\n",
    "\n",
    "normal_t = cal_average(features_normal_t)\n",
    "normal_v = cal_average(features_normal_v)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "\n",
    "rf_model = rf_model.fit(df_1, train['Label'])\n",
    "\n",
    "# predictions for un-selected features.\n",
    "rf_model_t = rf_model.predict(testing)\n",
    "\n",
    "# View accuracy score\n",
    "rf_test_sc = accuracy_score(test['Label'], rf_model_t)\n",
    "\n",
    "print(\"Test score is: \", normal_t)\n",
    "print(\"Valid score is: \", normal_v)\n",
    "print(\"The non selected score is: \", rf_test_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Bi-LSTM code: https://medium.com/analytics-vidhya/building-a-text-classification-model-using-bilstm-c0548ace26f2\n"
     ]
    }
   ],
   "source": [
    "# The links that will be used\n",
    "\n",
    "print(\"For the Bi-LSTM code: https://medium.com/analytics-vidhya/building-a-text-classification-model-using-bilstm-c0548ace26f2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from keras.layers import Dropout, Dense, Embedding, LSTM, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "import logging\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Import the tools we will need from keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize and fit the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train['Statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will build the Bi-LSTM model\n",
    "def bilstm_initialize(nclasses, dropout=0.5, hidden_layer = 3, lstm_node = 32):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(tokenizer.index_word)+1, 32))\n",
    "    for i in range(0,hidden_layer):\n",
    "        # Add a bidirectional lstm layer\n",
    "        model.add(Bidirectional(LSTM(lstm_node, return_sequences=True, recurrent_dropout=0.2)))\n",
    "        # Add a dropout layer after each lstm layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Bidirectional(LSTM(lstm_node, recurrent_dropout=0.2)))\n",
    "    model.add(Dropout(dropout))\n",
    "    # Add the fully connected layer with 256 nurons and relu activation\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    # Add the output layer with softmax activation since we have 6 classes\n",
    "    model.add(Dense(nclasses, activation='softmax'))\n",
    "    # Compile the model using sparse_categorical_crossentropy\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the score of the Neural Network model\n",
    "\n",
    "def get_eval_report(labels, preds):\n",
    "    mcc = matthews_corrcoef(labels, preds)\n",
    "    print(confusion_matrix(labels, preds))\n",
    "    print(confusion_matrix(labels, preds).ravel())\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    precision = (tp)/(tp+fp)\n",
    "    recall = (tp)/(tp+fn)\n",
    "    f1 = (2*(precision*recall))/(precision+recall)\n",
    "    return {\n",
    "        \"mcc\": mcc,\n",
    "        \"true positive\": tp,\n",
    "        \"true negative\": tn,\n",
    "        \"false positive\": fp,\n",
    "        \"false negative\": fn,\n",
    "        \"pricision\" : precision,\n",
    "        \"recall\" : recall,\n",
    "        \"F1\" : f1,\n",
    "        \"accuracy\": (tp+tn)/(tp+tn+fp+fn)\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_metrics(labels, preds):\n",
    "    assert len(preds) == len(labels)\n",
    "    return get_eval_report(labels, preds)\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 32)          397088    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 64)          16640     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 64)          24832     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, None, 64)          24832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 506,406\n",
      "Trainable params: 506,406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model_bilstm = bilstm_initialize(6)\n",
    "model_bilstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the categorical values numbers\n",
    "y_train = train[['Label']]\n",
    "y_test = test[['Label']]\n",
    "y_valid = valid[['Label']]\n",
    "\n",
    "\n",
    "# replace the y_training values\n",
    "y_train = y_train.replace('false', 0)\n",
    "y_train = y_train.replace('half-true', 1)\n",
    "y_train = y_train.replace('mostly-true', 2)\n",
    "y_train = y_train.replace('true', 3)\n",
    "y_train = y_train.replace('barely-true', 4)\n",
    "y_train = y_train.replace('pants-fire', 5)\n",
    "\n",
    "# replace the y_testing values\n",
    "y_test = y_test.replace('false', 0)\n",
    "y_test = y_test.replace('half-true', 1)\n",
    "y_test = y_test.replace('mostly-true', 2)\n",
    "y_test = y_test.replace('true', 3)\n",
    "y_test = y_test.replace('barely-true', 4)\n",
    "y_test = y_test.replace('pants-fire', 5)\n",
    "\n",
    "# replace the y_testing values\n",
    "y_valid = y_valid.replace('false', 0)\n",
    "y_valid = y_valid.replace('half-true', 1)\n",
    "y_valid = y_valid.replace('mostly-true', 2)\n",
    "y_valid = y_valid.replace('true', 3)\n",
    "y_valid = y_valid.replace('barely-true', 4)\n",
    "y_valid = y_valid.replace('pants-fire', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "80/80 [==============================] - 20s 140ms/step - loss: 1.7697 - accuracy: 0.1997 - val_loss: 1.7597 - val_accuracy: 0.1955\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 10s 122ms/step - loss: 1.7481 - accuracy: 0.1934 - val_loss: 1.7357 - val_accuracy: 0.2095\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 1.7349 - accuracy: 0.2109 - val_loss: 1.7194 - val_accuracy: 0.2204\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 1.7263 - accuracy: 0.2176 - val_loss: 1.7135 - val_accuracy: 0.2329\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 119ms/step - loss: 1.7182 - accuracy: 0.2255 - val_loss: 1.7136 - val_accuracy: 0.2111\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.7183 - accuracy: 0.2296 - val_loss: 1.7167 - val_accuracy: 0.2243\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.7045 - accuracy: 0.2425 - val_loss: 1.6183 - val_accuracy: 0.3045\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 1.5949 - accuracy: 0.3127 - val_loss: 1.4370 - val_accuracy: 0.3715\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 1.4727 - accuracy: 0.3741 - val_loss: 1.4481 - val_accuracy: 0.3551\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 10s 122ms/step - loss: 1.4349 - accuracy: 0.3846 - val_loss: 1.3822 - val_accuracy: 0.4050\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 1.4205 - accuracy: 0.3929 - val_loss: 1.3877 - val_accuracy: 0.3995\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 1.4077 - accuracy: 0.3994 - val_loss: 1.3698 - val_accuracy: 0.3956\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 1.3926 - accuracy: 0.4083 - val_loss: 1.3670 - val_accuracy: 0.4042\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.3852 - accuracy: 0.4085 - val_loss: 1.3695 - val_accuracy: 0.4073\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 1.3699 - accuracy: 0.4171 - val_loss: 1.3688 - val_accuracy: 0.3972\n"
     ]
    }
   ],
   "source": [
    "# Train the Bi-LSTM\n",
    "history = model_bilstm.fit(rf_2_train, y_train, \n",
    "                    batch_size=128, epochs=15,\n",
    "                    validation_data=(rf_2_valid, y_valid)) # test its accuracy with the validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the resulting accuracy and loss over the epochs\n",
    "plot_graphs(history, 'accuracy')\n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluating Model ... \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.57      0.41       249\n",
      "           1       0.33      0.43      0.38       265\n",
      "           2       0.38      0.46      0.42       241\n",
      "           3       0.91      0.15      0.26       208\n",
      "           4       0.75      0.19      0.31       212\n",
      "           5       0.58      0.58      0.58        92\n",
      "\n",
      "    accuracy                           0.39      1267\n",
      "   macro avg       0.55      0.40      0.39      1267\n",
      "weighted avg       0.52      0.39      0.38      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"\\n Evaluating Model ... \\n\")\n",
    "predicted = model_bilstm.predict_classes(rf_2_test)\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 29ms/step - loss: 1.4008 - accuracy: 0.3907\n",
      "Bi-LSTM :\n",
      "  Loss: 1.401\n",
      "  Accuracy: 0.391\n"
     ]
    }
   ],
   "source": [
    "# Determine its accuracy\n",
    "accr = model_bilstm.evaluate(rf_2_test,y_test)\n",
    "print('Bi-LSTM :\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "kModel = KerasClassifier(build_fn = lambda: bilstm_initialize(6), epochs=15, batch_size=128, verbose=1)\n",
    "kModel._estimator_type = \"classifier\"\n",
    "\n",
    "# Create a new random forest classifier for the most important features\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score\n",
    "\n",
    "def voting_class(nn, forest):\n",
    "    vote_test = VotingClassifier(\n",
    "     estimators=[('Bi-LSTM', kModel), ('rf', rf)],\n",
    "     voting='soft', weights=[nn,forest], flatten_transform=True)\n",
    "    \n",
    "    t = test['Label']\n",
    "    v = valid['Label']\n",
    "    \n",
    "    vote_test = vote_test.fit(rf_2_train, train[\"Label\"])\n",
    "    \n",
    "    vote_pred = vote_test.predict(rf_2_test)\n",
    "    \n",
    "    # get accuracy\n",
    "    vote_sc = accuracy_score(t, vote_pred)\n",
    "    \n",
    "    # get precision\n",
    "    vote_pre = precision_score(t, vote_pred, average=None)\n",
    "    \n",
    "    # get recall\n",
    "    vote_rec = recall_score(t, vote_pred, average=None)\n",
    "\n",
    "    return vote_sc, vote_pre, vote_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is turn:  1\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 18s 123ms/step - loss: 1.7704 - accuracy: 0.1935\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.7525 - accuracy: 0.1979\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 10s 122ms/step - loss: 1.7301 - accuracy: 0.2164\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.7316 - accuracy: 0.2286\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.7246 - accuracy: 0.2189\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.6972 - accuracy: 0.2437\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 1.6176 - accuracy: 0.2871\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 1.4877 - accuracy: 0.3565\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.4449 - accuracy: 0.3766\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.4137 - accuracy: 0.3818\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.4027 - accuracy: 0.3974\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.3955 - accuracy: 0.4020\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.3877 - accuracy: 0.4000\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.3752 - accuracy: 0.4164\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.3638 - accuracy: 0.4168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 30ms/step\n",
      "[0.4483030781373323]\n",
      "This is turn:  2\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 112ms/step - loss: 1.7716 - accuracy: 0.1988\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7538 - accuracy: 0.2076\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7347 - accuracy: 0.2166\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7228 - accuracy: 0.2117\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7196 - accuracy: 0.2298\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7135 - accuracy: 0.2378\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.6698 - accuracy: 0.2679\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.5474 - accuracy: 0.3299\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4471 - accuracy: 0.3740\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4278 - accuracy: 0.3881\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4106 - accuracy: 0.3989\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4025 - accuracy: 0.4057\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3889 - accuracy: 0.4102\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3917 - accuracy: 0.4099\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3757 - accuracy: 0.4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 28ms/step\n",
      "[0.4483030781373323, 0.4451460142067877]\n",
      "This is turn:  3\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 111ms/step - loss: 1.7678 - accuracy: 0.2053\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.7548 - accuracy: 0.2050\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7337 - accuracy: 0.2124\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7213 - accuracy: 0.2225\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7255 - accuracy: 0.2175\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7141 - accuracy: 0.2176\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.6851 - accuracy: 0.2521\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.5416 - accuracy: 0.3361\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4424 - accuracy: 0.3761\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4131 - accuracy: 0.3925\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4147 - accuracy: 0.3869\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4014 - accuracy: 0.4052\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3857 - accuracy: 0.4105\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3798 - accuracy: 0.4017\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3743 - accuracy: 0.4156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 27ms/step\n",
      "[0.4483030781373323, 0.4451460142067877, 0.452249408050513]\n",
      "This is turn:  4\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 109ms/step - loss: 1.7686 - accuracy: 0.2005\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7443 - accuracy: 0.2085\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7323 - accuracy: 0.2203\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7304 - accuracy: 0.2169\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7260 - accuracy: 0.2136\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7135 - accuracy: 0.2243\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6998 - accuracy: 0.2483\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.5902 - accuracy: 0.3135\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4829 - accuracy: 0.3656\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4402 - accuracy: 0.3876\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4107 - accuracy: 0.4009\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4098 - accuracy: 0.4080\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3910 - accuracy: 0.4116\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3819 - accuracy: 0.4157\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3775 - accuracy: 0.4156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 28ms/step\n",
      "[0.4483030781373323, 0.4451460142067877, 0.452249408050513, 0.44593528018942385]\n",
      "This is turn:  5\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 106ms/step - loss: 1.7704 - accuracy: 0.1984\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7532 - accuracy: 0.2036\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7375 - accuracy: 0.2169\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.7281 - accuracy: 0.2096\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7187 - accuracy: 0.2314\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.7157 - accuracy: 0.2355\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6848 - accuracy: 0.2521\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.5855 - accuracy: 0.3170\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4628 - accuracy: 0.3720\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4174 - accuracy: 0.3935\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4037 - accuracy: 0.4061\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.4009 - accuracy: 0.4075\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.3929 - accuracy: 0.4065\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3863 - accuracy: 0.4058\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3872 - accuracy: 0.4072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 27ms/step\n",
      "[0.4483030781373323, 0.4451460142067877, 0.452249408050513, 0.44593528018942385, 0.4514601420678769]\n",
      "This is turn:  6\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 107ms/step - loss: 1.7695 - accuracy: 0.1965\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.7530 - accuracy: 0.2044\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7340 - accuracy: 0.2072\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7217 - accuracy: 0.2196\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7127 - accuracy: 0.2331\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.6598 - accuracy: 0.2466\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.5525 - accuracy: 0.3371\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4458 - accuracy: 0.3753\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4134 - accuracy: 0.3877\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4057 - accuracy: 0.4050\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4046 - accuracy: 0.4009\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3893 - accuracy: 0.4080\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3845 - accuracy: 0.4019\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3693 - accuracy: 0.4129\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3664 - accuracy: 0.4159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 27ms/step\n",
      "[0.4483030781373323, 0.4451460142067877, 0.452249408050513, 0.44593528018942385, 0.4514601420678769, 0.4498816101026046]\n",
      "This is turn:  7\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 108ms/step - loss: 1.7709 - accuracy: 0.2049\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7541 - accuracy: 0.2034\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7297 - accuracy: 0.2190\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7272 - accuracy: 0.2250\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7235 - accuracy: 0.2231\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7119 - accuracy: 0.2292\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6766 - accuracy: 0.2545\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.5574 - accuracy: 0.3324\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4623 - accuracy: 0.3659\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4303 - accuracy: 0.3816\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4106 - accuracy: 0.3984\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3900 - accuracy: 0.4021\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3805 - accuracy: 0.3975\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3761 - accuracy: 0.4080\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3690 - accuracy: 0.4175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 28ms/step\n",
      "[0.4483030781373323, 0.4451460142067877, 0.452249408050513, 0.44593528018942385, 0.4514601420678769, 0.4498816101026046, 0.4506708760852407]\n",
      "This is turn:  8\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 109ms/step - loss: 1.7678 - accuracy: 0.1888\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7485 - accuracy: 0.1994\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7326 - accuracy: 0.2119\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7275 - accuracy: 0.2232\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7174 - accuracy: 0.2351\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6980 - accuracy: 0.2471\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.6357 - accuracy: 0.2783\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.5476 - accuracy: 0.3329\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4751 - accuracy: 0.3718\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4446 - accuracy: 0.3808\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4053 - accuracy: 0.3967\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4010 - accuracy: 0.4029\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3935 - accuracy: 0.4058\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3825 - accuracy: 0.4139\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3827 - accuracy: 0.4086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 27ms/step\n",
      "[0.4483030781373323, 0.4451460142067877, 0.452249408050513, 0.44593528018942385, 0.4514601420678769, 0.4498816101026046, 0.4506708760852407, 0.44672454617206]\n",
      "This is turn:  9\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 105ms/step - loss: 1.7711 - accuracy: 0.1924\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7463 - accuracy: 0.1971\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7343 - accuracy: 0.2093\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7224 - accuracy: 0.2291\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7194 - accuracy: 0.2300\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6896 - accuracy: 0.2446\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.5887 - accuracy: 0.3191\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.4785 - accuracy: 0.3590\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4372 - accuracy: 0.3874\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.4031 - accuracy: 0.3998\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3869 - accuracy: 0.4118\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3765 - accuracy: 0.4177\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3824 - accuracy: 0.4098\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3779 - accuracy: 0.4171\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3683 - accuracy: 0.4198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 28ms/step\n",
      "[0.4483030781373323, 0.4451460142067877, 0.452249408050513, 0.44593528018942385, 0.4514601420678769, 0.4498816101026046, 0.4506708760852407, 0.44672454617206, 0.4577742699289661]\n",
      "This is turn:  10\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 108ms/step - loss: 1.7678 - accuracy: 0.1868\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7522 - accuracy: 0.2004\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.7321 - accuracy: 0.2184\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7203 - accuracy: 0.2225\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7170 - accuracy: 0.2320\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7076 - accuracy: 0.2327\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.6096 - accuracy: 0.3030\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4921 - accuracy: 0.3607\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4364 - accuracy: 0.3830\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4176 - accuracy: 0.3930\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3990 - accuracy: 0.3960\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.4033 - accuracy: 0.4033\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.3831 - accuracy: 0.4146\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3737 - accuracy: 0.4174\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3717 - accuracy: 0.4130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 27ms/step\n",
      "[0.4483030781373323, 0.4451460142067877, 0.452249408050513, 0.44593528018942385, 0.4514601420678769, 0.4498816101026046, 0.4506708760852407, 0.44672454617206, 0.4577742699289661, 0.4498816101026046]\n",
      "[0.4483030781373323, 0.4451460142067877, 0.452249408050513, 0.44593528018942385, 0.4514601420678769, 0.4498816101026046, 0.4506708760852407, 0.44672454617206, 0.4577742699289661, 0.4498816101026046]\n",
      "The average for 1,2 is:  0.4498026835043409\n",
      "precision:  [0.45232626 0.43276498 0.40473701 0.43233103 0.65055128 0.5808322 ] \n",
      " 0.4922571280870649\n",
      "recall:  [0.3495283  0.48875502 0.50943396 0.593361   0.53478261 0.22548077] \n",
      " 0.4502236096680514\n"
     ]
    }
   ],
   "source": [
    "# Voting Ensemble\n",
    "arr = []\n",
    "pre = []\n",
    "rec = []\n",
    "f1 = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"This is turn: \", i+1)\n",
    "    score, precision, recall = voting_class(1,2)\n",
    "    f = (2*precision*recall)/(precision+recall)\n",
    "    arr.append(score)\n",
    "    pre.append(precision)\n",
    "    rec.append(recall)\n",
    "    f1.append(f)\n",
    "    print(arr)\n",
    "    \n",
    "print(arr)\n",
    "#TAKE FROM ME\n",
    "avg_slight_rf = cal_average(arr)\n",
    "prec_avg = cal_average(pre)\n",
    "rec_avg = cal_average(rec)\n",
    "f1_avg = cal_average(f1)\n",
    "\n",
    "total_prec = cal_average(prec_avg)\n",
    "total_rec = cal_average(rec_avg)\n",
    "total_f1 = cal_average(f1_avg)\n",
    "print(\"The average for 1,2 is: \", avg_slight_rf)\n",
    "print(\"precision: \", prec_avg, '\\n', total_prec)\n",
    "print(\"recall: \", rec_avg, '\\n', total_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration:  0\n",
      "Current array is:  [0.43804262036306235]\n",
      "Current iteration:  1\n",
      "Current array is:  [0.43804262036306235, 0.43804262036306235]\n",
      "Current iteration:  2\n",
      "Current array is:  [0.43804262036306235, 0.43804262036306235, 0.43804262036306235]\n",
      "Current iteration:  3\n",
      "Current array is:  [0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235]\n",
      "Current iteration:  4\n",
      "Current array is:  [0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235]\n",
      "Current iteration:  5\n",
      "Current array is:  [0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235]\n",
      "Current iteration:  6\n",
      "Current array is:  [0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235]\n",
      "Current iteration:  7\n",
      "Current array is:  [0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235]\n",
      "Current iteration:  8\n",
      "Current array is:  [0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235]\n",
      "Current iteration:  9\n",
      "Current array is:  [0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235, 0.43804262036306235]\n",
      "Current iteration:  0\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 18s 113ms/step - loss: 1.7690 - accuracy: 0.1965\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7587 - accuracy: 0.1935\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7300 - accuracy: 0.2120\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7238 - accuracy: 0.2088\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.7147 - accuracy: 0.2289\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.6994 - accuracy: 0.2485\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.6409 - accuracy: 0.2734\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.5462 - accuracy: 0.3360\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4456 - accuracy: 0.3895\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4115 - accuracy: 0.3987\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.4046 - accuracy: 0.3971\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.3821 - accuracy: 0.4106\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3805 - accuracy: 0.4129\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3622 - accuracy: 0.4265\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.3582 - accuracy: 0.4251\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 116ms/step - loss: 1.7684 - accuracy: 0.1906\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 1.7512 - accuracy: 0.2079\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 1.7289 - accuracy: 0.2152\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7241 - accuracy: 0.2259\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7074 - accuracy: 0.2511\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.6716 - accuracy: 0.2658\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.6292 - accuracy: 0.2868\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.5370 - accuracy: 0.3350\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4626 - accuracy: 0.3814\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.4068 - accuracy: 0.4007\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.4005 - accuracy: 0.4155\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3876 - accuracy: 0.4208\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3808 - accuracy: 0.4167\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3700 - accuracy: 0.4297\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3651 - accuracy: 0.4337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 29ms/step\n",
      "10/10 [==============================] - 2s 29ms/step\n",
      "Current array is:  [0.3780584056827151]\n",
      "Current iteration:  1\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 114ms/step - loss: 1.7680 - accuracy: 0.1900\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7420 - accuracy: 0.2114\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7241 - accuracy: 0.2163\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7214 - accuracy: 0.2223\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7098 - accuracy: 0.2242\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7065 - accuracy: 0.2353\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6904 - accuracy: 0.2453\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6841 - accuracy: 0.2546\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6676 - accuracy: 0.2756\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.5576 - accuracy: 0.3315\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4533 - accuracy: 0.3782\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4015 - accuracy: 0.4053\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3992 - accuracy: 0.4095\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3821 - accuracy: 0.4208\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3611 - accuracy: 0.4295\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 105ms/step - loss: 1.7691 - accuracy: 0.1944\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7582 - accuracy: 0.2047\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7346 - accuracy: 0.2161\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7244 - accuracy: 0.2079\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 10s 122ms/step - loss: 1.7101 - accuracy: 0.2275\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7094 - accuracy: 0.2462\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7066 - accuracy: 0.2504\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.6948 - accuracy: 0.2558\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6783 - accuracy: 0.2699\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6206 - accuracy: 0.3083\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.5300 - accuracy: 0.3481\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4411 - accuracy: 0.4007\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4044 - accuracy: 0.4067\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3716 - accuracy: 0.4297\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3671 - accuracy: 0.4344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 27ms/step\n",
      "10/10 [==============================] - 1s 25ms/step\n",
      "Current array is:  [0.3780584056827151, 0.3867403314917127]\n",
      "Current iteration:  2\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 106ms/step - loss: 1.7729 - accuracy: 0.1857\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.7510 - accuracy: 0.2060\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7224 - accuracy: 0.2179\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.7254 - accuracy: 0.2169\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.7123 - accuracy: 0.2295\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7059 - accuracy: 0.2386\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.6871 - accuracy: 0.2422\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6668 - accuracy: 0.2651\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.5781 - accuracy: 0.3067\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.4804 - accuracy: 0.3603\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4251 - accuracy: 0.3869\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4007 - accuracy: 0.3941\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3988 - accuracy: 0.4103\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3789 - accuracy: 0.4215\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3826 - accuracy: 0.4196\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 106ms/step - loss: 1.7713 - accuracy: 0.1890\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7570 - accuracy: 0.2085\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7263 - accuracy: 0.2212\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7228 - accuracy: 0.2201\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7118 - accuracy: 0.2374\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6964 - accuracy: 0.2474\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.6878 - accuracy: 0.2647\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.6751 - accuracy: 0.2727\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6252 - accuracy: 0.3124\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.5129 - accuracy: 0.3534\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4378 - accuracy: 0.3989\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4087 - accuracy: 0.4082\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3934 - accuracy: 0.4203\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3832 - accuracy: 0.4165\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3624 - accuracy: 0.4333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 27ms/step\n",
      "10/10 [==============================] - 1s 27ms/step\n",
      "Current array is:  [0.3780584056827151, 0.3867403314917127, 0.39621152328334647]\n",
      "Current iteration:  3\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 107ms/step - loss: 1.7720 - accuracy: 0.1838\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7509 - accuracy: 0.2036\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7243 - accuracy: 0.2197\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7214 - accuracy: 0.2228\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7107 - accuracy: 0.2473\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7041 - accuracy: 0.2461\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6664 - accuracy: 0.2605\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.5885 - accuracy: 0.3090\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4848 - accuracy: 0.3604\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4409 - accuracy: 0.3768\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3962 - accuracy: 0.3995\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3924 - accuracy: 0.4099\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3602 - accuracy: 0.4253\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3675 - accuracy: 0.4217\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3651 - accuracy: 0.4306\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 108ms/step - loss: 1.7712 - accuracy: 0.1926\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7472 - accuracy: 0.2054\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7278 - accuracy: 0.2229\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7236 - accuracy: 0.2200\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7061 - accuracy: 0.2384\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.6975 - accuracy: 0.2580\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.6845 - accuracy: 0.2649\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.6684 - accuracy: 0.2798\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.6456 - accuracy: 0.2982\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.5421 - accuracy: 0.3430\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4587 - accuracy: 0.3802\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3986 - accuracy: 0.4109\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 1.3858 - accuracy: 0.4201\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.3768 - accuracy: 0.4259\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.3752 - accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 27ms/step\n",
      "10/10 [==============================] - 1s 26ms/step\n",
      "Current array is:  [0.3780584056827151, 0.3867403314917127, 0.39621152328334647, 0.39857932123125495]\n",
      "Current iteration:  4\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 109ms/step - loss: 1.7730 - accuracy: 0.1848\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7552 - accuracy: 0.2063\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7330 - accuracy: 0.2073\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7186 - accuracy: 0.2164\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7145 - accuracy: 0.2224\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7087 - accuracy: 0.2406\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 1.6928 - accuracy: 0.2514\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.6526 - accuracy: 0.2741\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.5322 - accuracy: 0.3476\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.4475 - accuracy: 0.3876\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3971 - accuracy: 0.4134\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3878 - accuracy: 0.4218\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3852 - accuracy: 0.4224\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3654 - accuracy: 0.4385\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3423 - accuracy: 0.4443\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 106ms/step - loss: 1.7720 - accuracy: 0.2017\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7530 - accuracy: 0.1987\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7289 - accuracy: 0.2186\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7177 - accuracy: 0.2184\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7125 - accuracy: 0.2233\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.6872 - accuracy: 0.2403\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.6278 - accuracy: 0.2927\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.5235 - accuracy: 0.3444\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4505 - accuracy: 0.3801\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.4224 - accuracy: 0.3933\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.4005 - accuracy: 0.4077\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 1.3816 - accuracy: 0.4126\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3811 - accuracy: 0.4193\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3776 - accuracy: 0.4207\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3602 - accuracy: 0.4275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 26ms/step\n",
      "10/10 [==============================] - 1s 25ms/step\n",
      "Current array is:  [0.3780584056827151, 0.3867403314917127, 0.39621152328334647, 0.39857932123125495, 0.39226519337016574]\n",
      "Current iteration:  5\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 107ms/step - loss: 1.7700 - accuracy: 0.1906\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7505 - accuracy: 0.1988\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7255 - accuracy: 0.2038\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7221 - accuracy: 0.2157\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7183 - accuracy: 0.2195\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7059 - accuracy: 0.2498\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.6708 - accuracy: 0.2648\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.5968 - accuracy: 0.3185\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4941 - accuracy: 0.3700\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4099 - accuracy: 0.4114\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4095 - accuracy: 0.4130\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3784 - accuracy: 0.4230\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3671 - accuracy: 0.4262\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3679 - accuracy: 0.4264\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3614 - accuracy: 0.4308\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 108ms/step - loss: 1.7706 - accuracy: 0.1947\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7461 - accuracy: 0.2044\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7263 - accuracy: 0.2230\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7159 - accuracy: 0.2386\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7173 - accuracy: 0.2465\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7012 - accuracy: 0.2519\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.6984 - accuracy: 0.2639\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.6799 - accuracy: 0.2744\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.6228 - accuracy: 0.3072\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.5042 - accuracy: 0.3653\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4229 - accuracy: 0.4067\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3982 - accuracy: 0.4239\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4105 - accuracy: 0.4092\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3732 - accuracy: 0.4245\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3643 - accuracy: 0.4385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 27ms/step\n",
      "10/10 [==============================] - 1s 27ms/step\n",
      "Current array is:  [0.3780584056827151, 0.3867403314917127, 0.39621152328334647, 0.39857932123125495, 0.39226519337016574, 0.38910812943962114]\n",
      "Current iteration:  6\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 106ms/step - loss: 1.7702 - accuracy: 0.1840\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.7567 - accuracy: 0.2005\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.7260 - accuracy: 0.2127\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.7249 - accuracy: 0.2097\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.7144 - accuracy: 0.2267\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.6898 - accuracy: 0.2543\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 1.6819 - accuracy: 0.2541\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.6221 - accuracy: 0.3057\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 1.4953 - accuracy: 0.3595\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 1.4210 - accuracy: 0.3933\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.3870 - accuracy: 0.4108\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.3702 - accuracy: 0.4298\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.3666 - accuracy: 0.4261\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.3476 - accuracy: 0.4390\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.3364 - accuracy: 0.4404\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 106ms/step - loss: 1.7699 - accuracy: 0.1967\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7502 - accuracy: 0.2044\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7271 - accuracy: 0.2167\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7211 - accuracy: 0.2203\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7240 - accuracy: 0.2257\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7078 - accuracy: 0.2442\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6867 - accuracy: 0.2644\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.6524 - accuracy: 0.2670\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.5509 - accuracy: 0.3415\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.4610 - accuracy: 0.3701\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.4143 - accuracy: 0.4023\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3999 - accuracy: 0.4087\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3850 - accuracy: 0.4047\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3636 - accuracy: 0.4248\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3551 - accuracy: 0.4393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 26ms/step\n",
      "10/10 [==============================] - 1s 27ms/step\n",
      "Current array is:  [0.3780584056827151, 0.3867403314917127, 0.39621152328334647, 0.39857932123125495, 0.39226519337016574, 0.38910812943962114, 0.38910812943962114]\n",
      "Current iteration:  7\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 110ms/step - loss: 1.7705 - accuracy: 0.1867\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7482 - accuracy: 0.2004\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7297 - accuracy: 0.2066\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7176 - accuracy: 0.2145\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7031 - accuracy: 0.2327\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6900 - accuracy: 0.2537\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.6342 - accuracy: 0.2797\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.4857 - accuracy: 0.3648\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.4210 - accuracy: 0.3980\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.3935 - accuracy: 0.4057\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.3752 - accuracy: 0.4177\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.3864 - accuracy: 0.4196\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3607 - accuracy: 0.4263\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3571 - accuracy: 0.4328\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.3484 - accuracy: 0.4327\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 106ms/step - loss: 1.7721 - accuracy: 0.1917\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7540 - accuracy: 0.2111\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7236 - accuracy: 0.2189\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7194 - accuracy: 0.2215\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7119 - accuracy: 0.2380\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.6932 - accuracy: 0.2500\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.6406 - accuracy: 0.2962\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.5350 - accuracy: 0.3500\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.4527 - accuracy: 0.3914\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4327 - accuracy: 0.4008\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3941 - accuracy: 0.4195\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3788 - accuracy: 0.4240\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3863 - accuracy: 0.4273\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3592 - accuracy: 0.4333\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3636 - accuracy: 0.4384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 27ms/step\n",
      "10/10 [==============================] - 1s 27ms/step\n",
      "Current array is:  [0.3780584056827151, 0.3867403314917127, 0.39621152328334647, 0.39857932123125495, 0.39226519337016574, 0.38910812943962114, 0.38910812943962114, 0.3804262036306235]\n",
      "Current iteration:  8\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 106ms/step - loss: 1.7728 - accuracy: 0.1943\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7488 - accuracy: 0.1970\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7267 - accuracy: 0.2204\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7116 - accuracy: 0.2222\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.7023 - accuracy: 0.2380\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6987 - accuracy: 0.2439\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.6863 - accuracy: 0.2603\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.6570 - accuracy: 0.2688\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.5332 - accuracy: 0.3394\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.4207 - accuracy: 0.4066\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4044 - accuracy: 0.4084\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3723 - accuracy: 0.4223\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3646 - accuracy: 0.4357\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3597 - accuracy: 0.4378\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 1.3382 - accuracy: 0.4449\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 113ms/step - loss: 1.7691 - accuracy: 0.1949\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.7458 - accuracy: 0.2097\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.7293 - accuracy: 0.2128\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7184 - accuracy: 0.2241\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7181 - accuracy: 0.2296\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.7062 - accuracy: 0.2503\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.6972 - accuracy: 0.2646\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.6453 - accuracy: 0.2981\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.5690 - accuracy: 0.3345\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4648 - accuracy: 0.3846\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.4246 - accuracy: 0.4077\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.3852 - accuracy: 0.4262\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3840 - accuracy: 0.4177\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 1.3681 - accuracy: 0.4377\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 1.3679 - accuracy: 0.4371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 27ms/step\n",
      "10/10 [==============================] - 1s 25ms/step\n",
      "Current array is:  [0.3780584056827151, 0.3867403314917127, 0.39621152328334647, 0.39857932123125495, 0.39226519337016574, 0.38910812943962114, 0.38910812943962114, 0.3804262036306235, 0.39384372533543804]\n",
      "Current iteration:  9\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 16s 106ms/step - loss: 1.7715 - accuracy: 0.1911\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7494 - accuracy: 0.2143\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7257 - accuracy: 0.2125\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.7115 - accuracy: 0.2254\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.6916 - accuracy: 0.2415\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.6433 - accuracy: 0.2676\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 1.5462 - accuracy: 0.3400\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.4658 - accuracy: 0.3700\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.4114 - accuracy: 0.3957\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.4029 - accuracy: 0.4035\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3934 - accuracy: 0.4075\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3682 - accuracy: 0.4198\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.3688 - accuracy: 0.4187\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3703 - accuracy: 0.4228\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3692 - accuracy: 0.4273\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - 17s 106ms/step - loss: 1.7687 - accuracy: 0.1977\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 1.7455 - accuracy: 0.2099\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7238 - accuracy: 0.2231\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7145 - accuracy: 0.2264\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.7071 - accuracy: 0.2458\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.6957 - accuracy: 0.2594\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.6889 - accuracy: 0.2728\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.6549 - accuracy: 0.2986\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.5625 - accuracy: 0.3376\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.4680 - accuracy: 0.3803\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.4132 - accuracy: 0.4036\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.3913 - accuracy: 0.4183\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.3915 - accuracy: 0.4146\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.3634 - accuracy: 0.4328\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.3533 - accuracy: 0.4361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 28ms/step\n",
      "10/10 [==============================] - 1s 27ms/step\n",
      "Current array is:  [0.3780584056827151, 0.3867403314917127, 0.39621152328334647, 0.39857932123125495, 0.39226519337016574, 0.38910812943962114, 0.38910812943962114, 0.3804262036306235, 0.39384372533543804, 0.38752959747434884]\n",
      "The average for the BI-LSTM:  0.3891870560378847\n",
      "The average for the Random Forest:  0.3891870560378847\n"
     ]
    }
   ],
   "source": [
    "# Bagging Ensemble\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "arr_bag_rf = []\n",
    "arr_bag_nn = []\n",
    "\n",
    "def test_bagging_rf():\n",
    "    mod = BaggingClassifier(base_estimator=RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1),\n",
    "                         n_estimators=10, random_state=0)\n",
    "    \n",
    "    mod = mod.fit(rf_2_train, train[\"Label\"])\n",
    "    \n",
    "    t = test['Label']\n",
    "    v = valid['Label']\n",
    "    \n",
    "    mod_test = mod.predict(rf_2_test)\n",
    "    mod_score = accuracy_score(t, mod_test)\n",
    "    \n",
    "    return mod_score\n",
    "\n",
    "def test_bagging_nn():\n",
    "    mod = BaggingClassifier(base_estimator=kModel,\n",
    "                         n_estimators=2, random_state=0)\n",
    "    mod = mod.fit(rf_2_train, train[\"Label\"])\n",
    "    \n",
    "    t = test['Label']\n",
    "    v = valid['Label']\n",
    "    \n",
    "    mod_test = mod.predict(rf_2_test)\n",
    "    mod_score = accuracy_score(t, mod_test)\n",
    "    \n",
    "    return mod_score\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Current iteration: \", i)\n",
    "    \n",
    "    score = test_bagging_rf()\n",
    "    arr_bag_rf.append(score)\n",
    "    print(\"Current array is: \", arr_bag_rf)\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Current iteration: \", i)\n",
    "    \n",
    "    score = test_bagging_nn()\n",
    "    arr_bag_nn.append(score)\n",
    "    print(\"Current array is: \", arr_bag_nn)\n",
    "\n",
    "avg_bag_nn = cal_average(arr_bag_nn)\n",
    "avg_bag_rf = cal_average(arr_bag_nn)\n",
    "\n",
    "print(\"The average for the BI-LSTM: \", avg_bag_nn)\n",
    "print(\"The average for the Random Forest: \", avg_bag_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration:  0\n",
      "Current iteration:  1\n",
      "Current iteration:  2\n",
      "Current iteration:  3\n",
      "Current iteration:  4\n",
      "Current iteration:  5\n",
      "Current iteration:  6\n",
      "Current iteration:  7\n",
      "Current iteration:  8\n",
      "Current iteration:  9\n",
      "The average for boosting is:  0.4317284925019732\n"
     ]
    }
   ],
   "source": [
    "# Boosting ensemble\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "arr_boost = []\n",
    "\n",
    "def test_boosting():\n",
    "    boost_test = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "     max_depth=1, random_state=0)\n",
    "    \n",
    "    boost_test = boost_test.fit(rf_2_train, train[\"Label\"])\n",
    "    \n",
    "    t = test['Label']\n",
    "    v = valid['Label']\n",
    "\n",
    "    return boost_test.score(rf_2_test,t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Current iteration: \", i)\n",
    "    score = test_boosting()\n",
    "    arr_boost.append(score)\n",
    "\n",
    "avg_boost = cal_average(arr_boost)\n",
    "\n",
    "print(\"The average for boosting is: \", avg_boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model's Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,2,1])\n",
    "\n",
    "langs = [ 'Random Forest', 'Ensemble', 'Bi-LSTM', 'Bagging Random Forest', 'Bagging Bi-LSTM', 'Boosting']\n",
    "scores = [ normal_t-0.0, avg_slight_rf-0.0, accr[1]-0.0, avg_bag_rf, avg_bag_nn, avg_boost ]\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Testing set')\n",
    "\n",
    "ax.bar(langs,scores, bottom=0.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision of the model:  0.4922571280870649\n"
     ]
    }
   ],
   "source": [
    "print(\"The precision of the model: \" ,total_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recall of the model:  0.4502236096680514\n"
     ]
    }
   ],
   "source": [
    "print(\"The recall of the model: \", total_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1-score of the model:  0.4523502831908559\n"
     ]
    }
   ],
   "source": [
    "print(\"The f1-score of the model: \", total_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final accuracy of the ensemble model:  0.4498026835043409\n"
     ]
    }
   ],
   "source": [
    "print(\"The final accuracy of the ensemble model: \", avg_slight_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is:  0.44672454617206003\n",
      "Valid score is:  0.4369158878504673\n",
      "The non selected score is:  0.4230465666929755\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,2,1])\n",
    "\n",
    "langs = [ 'Random Forest', 'Random Forest Without Feature Selection']\n",
    "scores = [ normal_t-0.4, rf_test_sc-0.4 ]\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Testing set')\n",
    "\n",
    "ax.bar(langs,scores, bottom=0.4)\n",
    "plt.show()\n",
    "\n",
    "print(\"Test score is: \", normal_t)\n",
    "print(\"Valid score is: \", normal_v)\n",
    "print(\"The non selected score is: \", rf_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
